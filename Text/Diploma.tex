\documentclass[a4paper,12pt]{extarticle}
\usepackage[utf8]{inputenc} % Кодировка utf8
\usepackage[english, russian]{babel} % Языки: русский, английский
\usepackage{textcase}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[amsmath,thmmarks]{ntheorem}
\usepackage{MnSymbol}
\usepackage{listings}
\usepackage{hyperref}
\geometry{a4paper,top=2cm,bottom=2cm,left=3cm,right=1cm}
\theoremstyle{plain} % default
\newtheorem{theorem}{Теорема}
\newtheorem{proof}{Доказательство}
\begin{document}
\thispagestyle{empty}
\vspace*{2cm}

\thispagestyle{empty}
\begin{normalsize}
\begin{center}
{\bf МИНИСТЕРСТВО ОБРАЗОВАНИЯ РЕСПУБЛИКИ БЕЛАРУСЬ}
\end{center}

\begin{center}
{\bf БЕЛОРУССКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ}
\end{center}

\begin{center}
{\bf Факультет прикладной математики и информатики}
\end{center}

\begin{center}
Кафедра математического моделирования и анализа данных
\end{center}
\end{normalsize}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\begin{center}
{\bf МИРОНОВИЧ СВЕТЛАНА ЮРЬЕВНА}
\end{center}
\bigskip

\begin{center}
{\bf XS-схемы построения тактовых подстановок блочных криптосистем: характеристики перемешивания}
\end{center}
\bigskip
\bigskip
\bigskip
\bigskip

\begin{center}
Отчет по преддипломной практике\linebreak
студентки 5 курса 9 группы
\end{center}
\bigskip
\bigskip
\bigskip
\bigskip
%\begin{flushleft}
\linespread{1.0}
\begin{tabular}{@{}p{12cm}@{}p{5cm}}
{\small ''Допустить к защите''} & {\bf\small Научный руководитель}\\
{\small{}} & {\small Агиевич Сергей Валерьевич }\\
\begin{picture}(280,15)\put(140, 0){\line(1,0){140}}\end{picture}& {\small заведующий НИЛ ПБИТ} \\
\begin{picture}(140,15)\put(0,0){1 \quad\put(0,0){ марта {\small~ 2017 г}}}\end{picture} 
{}&{\small кандидат физ.-мат. наук}\\
\end{tabular}
%\end{flushleft}

\vspace{\stretch{1}}

\begin{center}
\bf{МИНСК 2017}
\end{center}
\begin{large}
\newpage
\tableofcontents
 
\clearpage

\newpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
\vspace*{1cm}

Современный мир невозможно представить без криптографии [1]. Телефонные звонки, сообщения в социальных сетях, интернет-банкинг - все это требует специальныx средств для защиты данных каждого пользователя. Как никогда остро стоит вопрос целостности (т.е. уверенность, что данные не были изменены) и конфиденциальности (т.е. необходимость предотвращения утечки или разглашения) информации [2]. Таким образом, знание о том, как сравнивать криптосистемы и находить наилучшую криптосистему из множества является прикладным.

С другой стороны, важной проблемой является быстродействие. Некоторые приложения в интернете, такие как видеозвоки, онлайн-трансляции, видеоконференции должны не только защищать целостность и конфиденциальность, но еще и работать "на лету". В данном случае важным параметром становится количество операций, необходимое для одного такта зашифрования.

Таким образом, для ряда задач требуются криптосистемы, которые для своего количества операций являются наиболее криптостойкими по некоторой заданной метрике, при этом чем меньше операций, тем лучше.

На текущий момент в криптографии принято разделять все криптосистемы на два вида: симметричные, которые в преобразованиях зашифрования и расшифрования используют один и тот же ключ, и асимметричные, которым для зашифрования и расшифрования требуются разные ключи [3]. Симметричные криптосистемы в свою очередь разделяются на блочные (когда исходный текст разбивается на блоки одинаковой длины и преобразование зашифрования применяется к каждому блоку) и поточные (когда генерируется гамма-последовательность, и шифртекст получается как результат применения операции XOR над исходным текстом и гамма-последовательностью)[4]. 

Тактовую подстановку блочной криптосистемы можно задать схемой~---
ориентированным графом, который описывает ход вычислений. В работе мы будем говорить о криптосистемах как о схемах и рассматривать свойства именно схем.

Тактовые подстановки блочных криптосистем можно классифицировать по операциям, которые применяются в одном такте подстановки на каждом фрагменте. Используют следующие операции:

\begin{itemize}
\item R
\newline Операция циклического сдвига
\item L
\newline Логические операции И и ИЛИ
\item S
\newline Замена на S-блоке
\item X
\newline Применение операции XOR над двумя фрагментами
\item A
\newline Сложение фрагментов длины m как чисел по модулю $2^m$
\end{itemize}

Различные сочетания этих операций дают различные типы схем. Так, криптосистемы SMS4 и Skipjack принадлежат к классу XS, AES можно отнести к классу XLS, а схемы криптосистем Salsa20, ChaCha и CAST-128 относятся к классу ARX[5].

Целью данной работы является исследование так называемых XS схем с целью нахождения оптимальной с точки зрения как криптостойкости, так и быстродействия схемы.

В отчете описываются способы задания $XS$ - схем. Затем рассматриваются две важные структуры, которые можно получить из схемы: граф разностных переходов и граф линейных переходов. Далее исследуются некоторые динамические характеристики данных графов, такие как легчаший путь из $l$ ребер и цикл с минимальным средним весом, и приводятся алгоритмы, вычисляющие эти характеристики. В заключении подводится итог проделанной за время преддипломной практики работы.


\newpage
\section{Построение схем $XS$}
%\addcontentsline{toc}{section}{Построение схем $XS$}
\vspace*{1cm}

Пусть на вход поступает двоичное слово $X$, из которого в ходе зашифрования получают $Y$. Тактовые подстановки функционируют следующим образом: $X$ разбивается на $n$ равных по длине частей $X_1, X_2, X_3, ..., X_n \in \{0, 1\}^m, X = X_1||X_2||X_3||...||X_n$. Фрагменты $X_i$ интерпретируются как вектора длины $m$ над полем $\{0, 1\}$. Затем вычисляется $Y_i, i = \overline{1,n}$ как комбинация фрагментов $X_j$ с некоторыми операциями, такими как битовый сдвиг, исключающее ИЛИ, сумма по модулю $2^m$, замена на S блоке, логическое И, логическо ИЛИ и т.д. Затем фрагменты $Y_i$ объединяются, чтобы получить выходное значение $Y: Y = Y_1||Y_2||Y_3||...||Y_n$. Здесь $n$ называют размерностью схемы, количество битов в $X_i, Y_i$ $m$ - размером фрагмента.

Рассмотрим схемы, в которых есть только операции замены на S-блоке и исключающее ИЛИ. Обозначим такие схемы как $XS$, подразумевая, что $X$ в названии $XS$ означает исключающее ИЛИ, $S$ означает замену на $S$ блоке. 

Все $XS$ схемы можно разделить на классы в зависимости от того, сколько различных $S$ блоков используется внутри схемы. Так, $XS_k$ обозначает такую $XS$-схему, в которой присутствует $k$ различных $S$ блоков. Таким образом, будет справедливо следующее: $XS = XS_1 \cup XS_2 \cup ... \cup XS_k \cup...$. Можно также провести аналогичное разделение по количеству операций исключающего ИЛИ, необходимых для одного такта, т.е. $X_lS_k$ - схема с $l$ сложениями по модулю 2 и $k$ заменами на $S$ блоке. Понятно, что значения $l, k$ характеризуют сложность схемы: чем они больше, тем схема сложнее.

Основным объектом изучения будут схемы с одним блоком $S$ и неограниченным количеством операций XOR, т.е. схемы $XS_1$. К схемам $XS_1$ можно отнести ряд тактовых подстановок, таких как Skipjack A, Skipjack B, SMS4. 

Схемы $XS$ размерности $n$ можно задать в виде матрицы $B = (b_{ij})$ размерности $n \times n$, вектора-строки $c = (c_i)$ размерности $n$ и вектора-столбца $a=(a_i)$ размерности $n$ следующим образом:

$$u = a_1X_1 + a_2X_2 + ... + a_nX_n$$
$$v = S(u)$$
$$Y_i = b_{1i}X_1 + b_{2i}X_2 + ... + b_{ni}X_n + c_iv, \forall i = \overline{1,n}$$

Здесь "+" обозначает операцию сложения по модулю 2, а $b_{ij}, a_i, c_i \in \{0, 1\}$, и соответственно, если $b_{ij} = 0 \vee c_j=0 \vee a_j = 0$, мы полагаем, что соответствющий вектор $X_j$ не участвует в сложении по модулю 2. В случае же, когда $b_{ij} = 1 \vee c_j=1 \vee a_j = 1$, соответствующий вектор $X_j$ включается в сложение.

Соответственно, преобразование можно задать в матричной форме:

$$y = xB + S(xa)c, x = (X_1, X_2, X_3, ..., X_n)$$.

В таком случае, видно, что вся схема $XS_1$ однозначно задается тройкой $(a, B, c)$. 

Также удобно записывать $(a, B, c)$ в виде следующей матрицы, которую будем называть расширенной:

$$
\begin{pmatrix}
b_{11} & b_{12} & \ldots & b_{1n} & a_1\\
b_{21} & b_{22} & \ldots & b_{2n} & a_2\\
\dotfill\\
b_{n1} & b_{n2} & \ldots & b_{nn} & a_n\\
c_1    & c_2    & \ldots & c_n    & 0\\
\end{pmatrix}.
$$

Рассмотрим на примере тактовой подстановки Skipjack A:

$$u = X_1$$
$$v = S(u)$$
$$Y_1 = X_4 + v$$
$$Y_2 = v$$
$$Y_3 = X_2$$
$$Y_4 = X_3$$

Или в виде расширенной матрицы:

$$
\begin{pmatrix}
0 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 0\\
1 & 0 & 0 & 0 & 0\\
1    & 1    & 0 & 0    & 0\\
\end{pmatrix}.
$$

\newpage
\section{Граф разностных переходов}
%\addcontentsline{toc}{section}{Граф разностных переходов}
\vspace*{1cm}

Пусть у нас есть схема $XS_1$ с параметрами $(a, B, c)$. Обозначим ее как $E$,  $E(X)$ - результат подстановки $X$ в схему $E$. 

Пусть также на вход схемы поступает два различных входа $X=X_1||X_2||...||X_n$ и $X'=X_1'||X_2'||X_3'||...||X_n'$, которые соответственно после проведения одного такта схемы преобразуются в $Y=Y_1||Y_2||Y_3||...||Y_n$ и $Y'=Y_1'||Y_2'||Y_3'||...||Y_n'$. Введем два вектора, $u$ и $v$ такие, что:

\begin{equation}
u_i=I\left\{X_i\ne X'_i\right\}=\left\{ \begin{array}{c}
1,X_i\ne X'_i \\
0,X_i=X'_i \end{array}
\right.i=1,\dots , n.
\end{equation}
\begin{equation}
v_i=I\left\{Y_i\ne Y'_i\right\}=\left\{ \begin{array}{c}
1,Y_i\ne Y'_i \\
0,Y_i=Y'_i \end{array}
\right.i=1,\dots , n.
\end{equation}

Будем называть $u$ разностным индикатором для $X$ и $X'$, и соответственно $v$ - это разностный индикатор $Y$ и $Y'$.

Говорят, из $u$ совершен разностный переход в $v$, когда существует два таких вектора $X$ и $X'$ такие, что $u$ - это их разностный индикатор, а $v$ является разностным индикаторов векторов $E(X) = Y, E(X') = Y'$.

$S$-блок при разностном переходе называется активным, если векторное произведение $(a, u) \neq 0$ (или, что то же самое, если $Xa \neq X'a$), поскольку в таком случае на вход $S$-блоку поступали разные вектора.

Тогда графом разностных переходов будем называть следующий ориентированный весовой граф. Его вершинами являются всевозможные битовые вектора длины $n$, и из вершины $u$ проведено ребро в вершину $v$ тогда и только тогда, когда из $u$ можно совершить разностный переход в $v$. Вес у этого ребра будет 1, если $S$-блок при таком разностном переходе является активным; в противном случае вес ребра будет 0.

Рассмотрим более подробно построоение графа разностных переходов на примере Skipjack A. Тактовая подстановка в Skipjack A выглядит, как упоминалось выше, следующим образом:

$$X_1, X_2, X_3, X_4 \rightarrow X_4 + S(X_1), S(X_1), X_2, X_3$$

Найдем, какие разностные переходы возможны из 1000.

Разностный индикатор 1000 для входных значений означает, что если нам на вход поступили вектора $X=X_1||X_2||X_3||X_4, X'=X_1'||X_2'||X_3'||X_4'$, то для них справедливо следующее: $X_1\neq X_1', X_2=X_2', X_3 = X_3', X_4 = X_4'$. 

Заметим, что поскольку $S$ биективна, то $A \neq B$ следует $S(A) \neq S(B)$.

Но в таком случае видно, что $Y_1=X_4 + S(X_1)=X_4' + S(X_1)\neq X_4' + S(X_1')=Y_1', Y_2=S(X_1)\neq S(X_1')=Y_2', Y_3=X_2=X_2'=Y_3', Y_4=X_3= X_3'=Y_4'$. Таким образом, разностный индикатор для $Y, Y'$ равен 1100. Более того, $S$-блок является активным.

Из этого следует, что в разностном графе существует ребро из 1000 в 1100 с весом 1, и аналогичным образом выстраиваются все ребра в графе разностных переходов.

Рассмотрим, как изменяются компоненты разностного индикатора при выполнении одного такта. Заметим, что поскольку мы имеем дело только с $XS_1$ схемами, нам достаточно рассмотреть, как влияют на разностный индикатор операторы исключающее ИЛИ и $S$-блок.


\textbf{$S$-блок}

Поскольку $S$-блок биективен, то $A \neq B$ тогда и только тогда, когда $S(A) \neq S(B)$. Это равносильно тому, что заметить следующее: пусть $u$ - некоторый разностный индикатор. Тогда если применить $S$-блок к фрагментам обоих исходных векторов, из которых получен данный разностный индикатор, и посчитать разностный индикатор результата (условно можем обозначить его $S(u)$), то снова получится вектор $u$, т.е. нули вектора $u$ перейдут в нули вектора $S(u)$, единицы перейдут в единицы. Или, что то же самое, $u=S(u)$.

\textbf{Исключающее ИЛИ}

 Как было доказано в [6], для исключающего ИЛИ на разностных индикаторах (введем для этой операции специальное обозначение $\odot$) справедливы следующие соотношения:

\begin{itemize}
\item $0 \odot 0 = 0$
\item $0 \odot 1 = 1$
\item $1 \odot 0= 1$
\item $1 \odot 1 = 0$ и 1. 
\end{itemize}

Например, применим данную операцию к следующим векторам: 01101 и 11001. Получим:

$$01101 \odot 11001 = 1~_{1}^010~_{1}^0 = \{10100, 11100, 10101, 11101\}$$.

Введем также для удобства следующую бинарную операцию: $(u, v)^{\odot} = u_1v_1 \odot u_2v_2 \odot ... \odot u_nv_n$.

Поскольку мы знаем, как влияют операции $S$-блока и исключающее ИЛИ на разностные индикаторы, то мы можем теперь записать алгоритм построения графа разностных переходов:

\begin{algorithm}[H]
\caption{Алгоритм построения графа разностных переходов}
\label{diff_graph_construct}
\textbf{Вход:} $XS_1$-схема $(a, B, c), n$ - размерность схемы.\\
\textbf{Выход:} Граф разностных переходов для схемы $(a, B, c)$.\\
Шаг 0. Создаем квадратную матрицу res размера $2^n$ и заполняем ее -1. \\
Шаг 1. Для каждого вектора $v, v \in \{0, 1\}^n$ выполняем следующее: \\
Шаг 2.1 Вычисляем вес ребер $w$, исходящих из вершины, соответствующей вектору $v$, следующим образом: $w = 0~ if (a,v) = 0 ~else ~1$.\\
Шаг 2.2 Находим все вершины, куда ведут исходящие из $v$ ребра, следующим образом: $i$-тая координата вершины определяется как $(v, B_i)^{\odot} \odot c_iw$, где $B_i$ - это $i$-тый столбец $B$. \\
Шаг 2.3 Для всех найденных вершин $v'$, куда будут вести ребра из $v$, пишем $res[v][v'] = w$.
Шаг 3. Возвращаем $res$.\\
\end{algorithm}

Очевидно, что сложность алгоритма будет зависеть от входа $(a,B,c)$ и будет не превышать $2^{2n}$.

\newpage
\section{Граф линейных переходов}
%\addcontentsline{toc}{section}{Граф линейных переходов}

Пусть у нас есть схема $XS_1$ с параметрами $(a, B, c)$. Обозначим ее как $E$,  $E(X)$ - результат подстановки $X$ в схему $E$. 

Пусть также на вход тактовой подстановки поступает $X = X_1||X_2||...||X_n$, и $Y=E(X) = Y_1||Y_2||...||Y_n$.

Индикатором $q = (q_1, q_2, ..., q_n)$ для вектора $a=(a_1, a_2, ..., a_n)$ будем называть следующий вектор:

\begin{equation}
q_i=I\left\{a_i\ne 0\right\}=\left\{ \begin{array}{c}
1,a_i \neq 0 \\
0,a_i = 0\end{array}
\right.i=1,\dots , n.
\end{equation}

Рассмотрим следующее соотношение:

\begin{equation}
\label{eq:lin_proportion}
\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n
\end{equation}

Это соотношение должно выполняться для всех $X_1, X_2, ..., X_n$.

Понятно, что поскольку $Y_i$ является линейной комбинацией из $X_1, X_2, ..., X_n$, $S(a_1X_1 + a_2X_2 + ... + a_nX_n)$, то тогда соотношение можно переписать следующим образом:

\begin{equation}\label{eq:in_gamma}
\gamma_1X_1 + \gamma_2X_2 + ... + \gamma_nX_n = \gamma S(a_1X_1 + a_2X_2 + ... + a_nX_n)\end{equation}

Обозначим $q=(q_1, q_2, ..., q_n)$ как идентификатор для $\alpha=(\alpha_1, \alpha_2, ..., \alpha_n)$, $r=(r_1, r_2, ..., r_n)$ идентификатор для $\beta = (\beta_1, \beta_2, ..., \beta_n)$. И тогда про $q$ и $r$ можно сказать следующее: из $q$ совершен линейный переход в $r$. 

$S$-блок будет называться линейно активным, если $\gamma \neq 0$.

Теперь мы можем ввести определение графа линейных переходов. Графом линейных переходов будем называть такой ориентированный весовой граф, у которого вершинами являются вектора $\{0, 1\}^n$, и из вершины $q$ есть ребро в вершину $r$ тогда и только тогда, когда существуют такие $\alpha = (\alpha_1, \alpha_2, ..., \alpha_n)$, $\beta = (\beta_1, \beta_2, ..., \beta_n)$, что для любых $X_1, X_2, ..., X_n$ выполняется $\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n$, и притом $q, r$ являются соответственно индикаторами для $\alpha, \beta$. Ребро из $q$ в $r$ имеет вес 1, если $S$-блок является в данном соотношении линейно активным; иначе вес ребра равен 0.

Как было доказано в [6], для соотношений выше справедливы следующие свойства:

 \begin{equation} \label{eq:lin_property1} 1) a_i = 0 \rightarrow \gamma_i = 0 \end{equation}
 \begin{equation} \label{eq:lin_property2} 2) a_i = a_j = 1 \rightarrow \gamma_i = \gamma_j  
 \end{equation}
\begin{equation} \label{eq:lin_property3} 3)(\ref{eq:in_gamma}) \Rightarrow \rho (Xa) = \gamma S(Xa) \end{equation}

Воспользуемся этими свойствами, чтобы найти всевозможные линейные соотношения. Для этого сначала распишем уравнение (\ref{eq:lin_proportion}) так, чтоб в нем не осталось $Y_1, Y_2, ..., Y_n$. Для этого сначала введем обозначения и запишем исходное соотношение:

$$v = S(a_1X_1 + a_2X_2 + ... + a_nX+n)$$
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n \Rightarrow$$
Теперь распишем каждый $Y_i$ через $X_1, X_2, ..., X_n$.
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1(b_{11}X_1 + b_{21}X_2 + ... + b_{n1}X_n + c_1v) +$$
$$ +  \beta_2(b_{12}X_1 + b_{22}X_2 + ... + b_{n2}X_n + c_2v) +$$
$$+~ ...~ +$$
$$+ \beta_n(b_{1n}X_1 + b_{2n}X_2 + ... + b_{nn}X_n + c_nv) $$
Затем перегруппируем в правой части слагаемые так, чтобы можно было выделить слагаемые с $X_1$, с $X_2$, ..., с $X_n$:
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = (\beta_1b_{11} + \beta_2b_{12} + ... + \beta_nb_{1n})X_1 + $$
$$+(\beta_1b_{21} + \beta_2b_{22} + ... + \beta_nb_{2n})X_2 + ... + (\beta_1b_{n1} + \beta_2b_{n2} + ... + \beta_nb_{nn})X_n+$$
$$+ (\beta_1c_1 + \beta_2c_2 + ... + \beta_nc_n)v$$
И перенесем все слагаемые с $X_1, X_2, ..., X_n$ в левую часть, оставив в правой только те слагаемые, в которых присутствует $v$:
$$ (\alpha_1 + \beta_1b_{11} + \beta_2b_{12} + ... + \beta_nb_{1n})X_1 + (\alpha_2 + \beta_1b_{21} + \beta_2b_{22} + ... + \beta_nb_{2n})X_2 + $$
$$+...+ (\alpha_n + \beta_1b_{n1} + \beta_2b_{n2} + ... + \beta_nb_{nn})X_n =  (\beta_1c_1 + \beta_2c_2 + ... + \beta_nc_n)v$$
Перейдем теперь от векторов $\alpha_i, \beta_i$ к их индикаторам $\alpha_i', \beta_i'$ (и соответственно, переходим от операции исключающее ИЛИ к операции $\odot$):
$$ (\alpha_1' \odot \beta_1'b_{11} \odot \beta_2'b_{12} \odot ... \odot \beta_n'b_{1n})X_1 \odot (\alpha_2' \odot \beta_1'b_{21} \odot \beta_2'b_{22} \odot ... \odot \beta_n'b_{2n})X_2 \odot $$
$$\odot...\odot (\alpha_n' \odot \beta_1'b_{n1} \odot \beta_2'b_{n2} \odot ... \odot \beta_n'b_{nn})X_n =  (\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n)v = $$
\begin{equation}\label{eq:not_final_lin}=(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n)S(a_1X_1 \odot a_2X_2 \odot ... \odot a_nX_n)\end{equation}
И в таком случае видно, что для всех тех $i$, таких что $a_i = 0$, коэффициенты при $X_i$ должны зануляться, поскольку при $a_i = 0$ правая часть не зависит от $X_i$, и следовательно, от $X_i$ не должна зависеть и левая часть. Получаем следующее соотношение: 
$$\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = 0 ~ \forall i: ~a_i = 0$$
А для всех $i$ таких, что $a_i = 1$, ясно, что справедливо следующее:
$$\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = (\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i: ~a_i = 1$$
И теперь можем записать эти выражения в общем виде:
\begin{equation}\label{eq:slau}\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = a_i(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i=\overline{1,n} \end{equation}
Или, если оставить $\alpha_i'$ на одной стороне, а $\beta_i'$ - на другой, получим:
\begin{equation}\label{eq:final_lin}\alpha_i' = \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} \odot a_i(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i=\overline{1,n} \end{equation}
Заметим также, что $S$-блок будет линейно активным, как следует из (\ref{eq:slau}), тогда и только тогда, когда скалярное произведение $(\alpha', a)$ будет строго больше нуля.

И теперь при помощи (\ref{eq:final_lin}) можем записать алгоритм построения графа линейных переходов.

\begin{algorithm}[H]
\caption{Алгоритм построения графа линейный переходов}
\label{diff_graph_construct}
\textbf{Вход:} $XS_1$-схема $(a, B, c), n$ - размерность схемы.\\
\textbf{Выход:} Граф линейных переходов для схемы $(a, B, c)$.\\
Шаг 0. Создаем квадратную матрицу res размера $2^n$ и заполняем ее -1. \\
Шаг 1. Для каждого вектора $\beta, \beta \in \{0, 1\}^n$ выполняем следующее: \\
Шаг 1.1. Находим все возможные $\alpha$, соответствующие этому $\beta$, подставляя $\beta$ в \ref{eq:final_lin}.\\
Шаг 1.2. Для каждого найденного вектора $\alpha$ делаем следующее:\\
Шаг 1.2.1. Вычисляем вес ребра $w$, исходящего из вершины $\alpha$, как $w = 0~ if~ (\alpha, a) = 0~ else~1$ \\
Шаг 1.2.2. Записываем в матрицу $res$ следующее: $res[\alpha][\beta] = w$.\\
Шаг 2. Возвращаем $res$.\\
\end{algorithm} 

\newpage
\section{Алгоритмы расчетов динамических характеристик графов переходов}
%\addcontentsline{toc}{section}{Алгоритмы расчетов динамических характеристик графов переходов}

Для криптографической стойкости схемы важными характеристикиками являются следующие две величины [6]: минимальный вес пути заданной длины на графах линейных и разностных переходов, а также минимальноге отношение веса цикла к его длине на обоих графах.

Абстрагируемся от того, какой именно граф поступает нам на вход, линейных или разностных переходов, и просто обозначим его как $G$. Мы можем так поступить, поскольку свойства обоих графов очень схожи: оба графа являются ориентированными, у их ребер есть веса, причем вес может быть только 0 или 1, а также нет ребер, ведущих в вершину 000...0.

Для упрощения записи переименуем вершины графа $G$. В графах линейных и разностных переходов вершинами являются вектора из $\{0, 1\}^n$. Тогда пусть в $G$ вершин будут целыми числами, и тогда вершине $k$ из $G$ будет соответствовать на самом деле вершина $l$ из $\{0, 1\}^n$ такая, что $l$ - это битовая запись $k$.

\subsection{Минимальный вес пути заданной длины}

Будем полагать, что путь - это последовательность из вершин и ребер, которую можно записать следующим образом: $v_1, e_1, v_2, e_2, ..., e_mv_{m+1}$, где $e_i$ - это ребро, ведущее из $v_i$ в $v_{i+1}$. Тогда длина пути - это количество ребер в нем $m$, а вес - это сумма весов входящих в путь ребер. Также будем полагать, что ребра могут повторяться.

Обозначим как $V$ множество вершин графа $G$, $E$ - множество ребер графа $G$, $n$ - количество вершин в графе, $m$ - количество ребер в графе. Также пусть $(u, v) \in E$ - некоторое ребро, тогда его вес будем обозначать как $w(u, v)$.

Пусть нас интересует, какой минимальный вес пути длины $l$ на всем графе. Для этого будем искать пути минимального веса длины $l$ до каждой из вершин. Понятно, что вообще говоря кратчайший путь длины $l$ до любой из вершин может также и начинаться в любой вершине, поэтому сведем эту задачу к более известной: нахождение самого легкого пути длины $l$ до всех остальных вершин, причем путь всегда начинается из одной и той же вершины $v_{-1}$. Данная постановка задачи очень схожа с постановкой задачи в алгоритме Форда-Беллмана, в котором требуется найти легчайшие пути из заданной вершины до всех остальных (без учета длины). Вершина $v_{-1}$ является фиктивной, и будем полагать, что из $v_{-1}$ есть ребра до всех вершин из $V$, но нет ни одного ребра, ведущего в $v_{-1}$. Ребрам из $v_{-1}$ присвоим веса 0. В таком случае, нахождение легчайших путей длины $l$ до каждой из вершин в графе $G$ равнозначно нахождению легчайших путей длины $l+1$ из вершины $v_{-1}$ до всех остальных вершин.

 Рассмотрим алгоритм Беллмана-Форда и попытаемся модифицировать его согласно нашим нуждам.

\begin{algorithm}[H]
\caption{Алгоритм Беллмана-Форда}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$ и стартовая вершина $s$, от которой нужно найти вес легчайших путей до всех остальных вершин.\\
\textbf{Выход:} Массив $d$, в котором $d[v]$ содержит вес самого легкого пути из заданной вершины до вершины $v$.\\
Шаг 0. Создаем массив $d$ длины $n$ и заполняем его $+\infty$. \\
Шаг 1. Записываем $d[s] = 0$.\\
Шаг 2. Для $i$ от 1 до $n-1$ делаем следующее:\\
Шаг 2.1 Для всех ребер $(u, v) \in E:$\\
Шаг 2.1.1 Если $d[v] > d[u] + w(u,v)$, то $d[v] = d[u] + w(u,v)$\\
Шаг 3. Возвращаем $d$.\\
\end{algorithm}

Очевидно, сложность данного алгоритма $O(nm)$.

Видно, что основная проблема алгоритма Беллмана-Форда для нас заключается в том, что мы никак не фиксируем и не контролируем длину пути в ребрах. Теперь видоизменим алгоритм, и внешний цикл в нем сделаем не до $n$, а до $l$, где $l$ --- длина пути, чей минимальный вес мы ищем. Также на каждом шаге $k$ будем создавать новый массив $d_k$, в котором будут храниться минимальные веса длины $k$ до каждой из вершин. Запишем новый алгоритм:

\begin{algorithm}[H]
\caption{Модифицированный Алгоритм Беллмана-Форда}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$.\\
\textbf{Выход:} Массив $\pi_l$, в котором $\pi_l[v]$ содержит самый легкий путь длины $l$ до вершины $v$.\\
Шаг 0. Создаем массив $\pi_0$ длины $n$ и заполняем его $0$. \\
Шаг 1. Для $k$ от 1 до $l$ делаем следующее:\\
Шаг 1.1 Создаем массив $\pi_k$ и заполняем его $+\infty$,\\
Шаг 1.2 Для всех ребер $(u, v) \in E:$\\
Шаг 2.1.1 Если $\pi_k[v] > \pi_{k-1}[u] + w(u,v)$, то $\pi_k[v] = \pi_{k-1}[u] + w(u,v)$\\
Шаг 3. Возвращаем $\pi_l$.\\
\end{algorithm}

\begin{theorem}
Относительно модифицированного алгоритма Беллмана-Форда справедливо следующее:
1) Алгоритм решает задачу поиска кратчайших путей длины $l$ до каждой из вершин графа.
2) Алгоиртмическая сложность алгоритма: $O(lm)$.
\end{theorem}
\textbf{Доказательство}
Докажем каждое утверждение теоремы поотдельности.

1) Докажем данное утверждение методом индукции.

База индукции: на нулевом шаге в $\pi_0$ хранятся оптимальные веса.

Действительно, поскольку веса всех ребер неотрицательные, то и вес любого пути в графе обязательно $\ge$ 0. Следовательно, не может в графе существовать пути, вес которого меньше 0. Но на данном этапе в $\pi_0$ хранятся только нули, и следовательно, $\pi_0$ хранит минимальные по весу пути длины 0.

Индуктивный шаг: пусть на шагах $1, 2, ..., k-1$ были найдены минимальные по весу пути до каждой вершины длины $1, 2, ..., l-1$. Докажем, что и на $l$-том шаге будут найдены оптимальные пути. Положим от противного, это не так. Т.е. существует вершина $v'$, до которой существует путь длины $l: ~ v_1'e_1'v_2'e_2'v_3'...e_l'v'$, такой что $\sum_{i=1}^l w(e_i') < \pi_l[v']$. Но поскольку на шаге 1.2 алгоритма мы проходили по всем ребрам, мы должны были пройти и по ребру $(v_l', v')$. И поскольку $\pi_l[v'] > \sum_{i=1}^l w(e_i') = \pi_{l-1}[v_{l}'] + w( (v_l', v'))$, то на шаге 2.1.1 алгоритма мы должны были бы записать в $\pi_l[v'] = \pi_{l-1}[v_{l}'] + w( (v_l', v'))$, т.е. выбрать другой путь. И в таком случае на самом деле $\pi_l[v'] =  \sum_{i=1}^l w(e_i') $, и это противоречит предположению о том, что $\pi_l[v'] > \sum_{i=1}^l w(e_i')$. Следовательно, алгоритм действительно находит легчайшие пути заданной длины до всех вершин.

2) Это утверждение следует из того, что в алгоритме содержится только два вложенных цикла: один по длине пути, и один по всем ребрам. Один цикл повторяется $l$ раз, другой - $m$ (и оба цикла обязательно проходятся, т.е. нет пропуска итераций). Следовательно, сложность будет $O(lm)$.
$\boxtimes$

\bigskip

Теперь вспомним, что изначально нас интересовал путь наименьшего веса длины $l$ безотносительно того, где этот путь заканчивается. Обозначим данную величину за $\Pi_l$. Тогда очевидно, что искомая величина может быть найдена по $\pi_l$ следующим образом: $$\Pi_l = \min_{v \in V} \pi_l[v]$$.

\subsection{Цикл минимального среднего веса}

Постановка задачи звучит следующим образом: пусть у нас есть ориентированный граф $G$, ребрам которого присвоены веса. Требуется найти следующую величину:

$$\Lambda = \min _{c \in C} \frac{w(c)}{l(c)},$$

где $C$ - множество всех циклов графа $G$, $w(c)$ - вес цикла $c$, $l(c)$ - длина цикла $c$. Здесь длина цикла - это количество ребер в нем $n$, а вес цикла - это сумма весов всех входящих в него ребер.

Сначала в процессе исследований был предложен алгоритм, базирующийся на модифицированном алгоритме Беллмана-Форда. В основу были взяты рассуждения о том, что асимптотически величина $\frac{\Pi_N}{N}$ стемится к $\Lambda$.  И действительно, при $N \rightarrow \infty$ мы обязательно начнем ходить по какому-нибудь циклу. В таком случае величина $\Pi_N$ представима в виде суммы веса предцикла (т.е. тех ребер, с которых мы стартовали путь длины $N$ и которые не входят в цикл), цикла и послецикла (последние ребра, которые также не входят в цикл). Понятно, что длины предцикла и послецикла ограничены сверху количеством вершин в графе $n$. И тогда вес легчайшего пути при длине, стремящейся к бесконечности, может быть записан следующим образом:

$$\Pi_N = w(beforecycle) + \frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}w(cycle) + w(aftercycle)$$

Обозначим полное число оборотов, который совершит цикл, за $rot$, т.е. :

$$rot =  \frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}$$

Ограничим сверху и снизу величину $\Pi_N$, используя тот факт, что $0 \le w(beforecycle) \le n$ и $0 \le w(aftercycle) \le n$:

$$rot \cdot w(cycle) \le \Pi_N \le 2n + rot \cdot w(cycle).$$

И теперь разделим это выражение на длину пути в ребрах $N$:

\begin{equation}\label{eq:pi_divided_N}
\frac{rot}{N} \cdot w(cycle) \le \frac{\Pi_N}{N} \le \frac{2n}{N} + \frac{rot}{N} \cdot w(cycle).\end{equation}
Очевидно следующее:

$$\frac{rot}{N} w(cycle) = \frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}\frac{w(cycle)}{N}=$$
$$=\frac{N - l(aftercycle) - l(beforecycle)}{N}\frac{w(cycle)}{l(cycle)} =$$
$$= \frac{N - l(aftercycle) - l(beforecycle)}{N} \cdot mean(cycle) \rightarrow_{N \rightarrow \infty} mean(cycle)$$

Аналогично:

$$\frac{2n}{N} + \frac{rot}{N} \cdot w(cycle) \rightarrow mean(cycle)$$

А тогда из (\ref{eq:pi_divided_N}) при $N \rightarrow \infty$ следует:

$$mean(cycle) \le \lim_{N \rightarrow \infty} \frac{\Pi_N}{N} \le mean(cycle) \Rightarrow \lim_{N \rightarrow \infty}\frac{\Pi_N}{N} = mean(cycle)$$

Очевидно, что поскольку мы используем $\Pi_N$, которое означает минимальный вес пути длины $N$, то тогда и $mean(cycle)$ на самом деле будет использовать такой цикл, в котором средний вес минимален.

И тогда можно было бы находить величину $\Lambda$ при помощи величин в из массива $\pi_N$.

Заметим также, что нам достаточно находить простые циклы (т.е. те циклы, в которых каждая вершина встречается только один раз), поскольку любой цикл с повторениями вершин можно разбить на простые циклы, и среди простых циклов обязательно найдется цикл со значением среднего не больше, чем у исходного не простого цикла. Можно доказать это следующим образом: пусть нам дан исходный цикл из ребер $e_1, e_2, ..., e_k$ (вообще говоря, ребра могут повторяться. Порядок указания ребер также важен). Если этот цикл не является простым, то он обязательно разбивается на простые, причем следующим образом: в первый цикл входят ребра $e_1, e_2, ..., e_{k_1}$, во второй - $e_{k_1+1}, e_{k_1+2}, ..., e_{k_2}$, и так далее до последнего, $l$-того цикла $e_{k_{l-1}+1}, e_{k_{l-1}+2}, ..., e_{k_l},$ $(e_{k_l} = e_k)$.  Теперь положим от противного, средний вес всех простых циклов строго больше среднего веса исходного цикла. Обозначим средний вес исходного цикла за $mean_{src}$, а средние веса всех простых циклов как $mean_1, mean_2,$ $..., mean_l$. Но тогда мы получаем:

$$mean_{src} * k = w(e_1) + w(e_2) + ... + w(e_k) =$$
$$= k_1\frac{(w(e_1) +  w(e_2) +  ... + w(e_{k_1}))}{k_1} + k_2\frac{(w(e_{k_1+1}) + w(e_{k_1+2}) + ... + w(e_{k_2}))}{k_2} +$$
$$+ ... + k_l\frac{(w(e_{k_{l-1}+1}) + w(e_{k_{l-1}+2}) + ... + w(e_{k_l})}{k_l}) = $$
$$=k_1mean_1 ~+ ~k_2mean_2 ~+ ~... ~+ ~k_lmean_l~ >$$
$$> k_1mean_{src}~ +~ k_2mean_{src}~ +~ ...~ +~ k_lmean_{src} = (k_1 + k_2 + ... + k_l)mean_{src} = k \cdot mean_{src}$$

Т.е. мы получили следующее:

$$k \cdot mean_{src} > k \cdot mean_{src}$$

Это противоречие, и следовательно, предположение не верно. А это означает, что достаточно просматривать только простые циклы в графе, чтобы найти цикл минимального среднего веса.

Теперь, оперируя доказанными утверждениями (а именно то, что достаточно только простых циклов, а также утверждение про взаимосвязь $\Pi_N$ и $\Lambda$), составим алгоритм нахождения $\Lambda$ на основании модифицированного алгоритма Беллмана-Форда.

\begin{algorithm}[H]
\caption{Алгоритм нахождения $\Lambda$}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$\\
\textbf{Выход:} $\Lambda$.\\
Шаг 0. Вычислим все вектора $\Pi_i$ для $i = \overline{1, ITER}$. Также в процессе подсчета $\Pi_i$ создадим вектора $prev_i$, где $prev_i[v]$ хранит значение, из какой вершины был совершен последний переход в вершину $v$ по легчайшему пути длины $i$.\\
Шаг 1. Присваиваем $minMean = \infty$.\\
Шаг 2. Для каждой вершины $v \in V$, для которой справедливо $\Pi_{ITER}[v] \ne \infty$, делаем следующее:\\
Шаг 2.1. Восстанавливаем последний цикл, который содержится в легчайшем пути длины $ITER$, ведущим в $v$. Это вычисляется следующим образом:\\
Шаг 2.2. Создаем пустой вектор и пустое хэш-множество $visitedVerticesArray$ и $visitedVerticesSet$.\\
Шаг 2.3. Записываем $currentVertice = v; iteration = ITER$.\\
Шаг 2.3. Пока $currentVertice \notin visitedVerticesSet$:\\
Шаг 2.3.1. Добавляем $currentVertice$ в $visitedVerticesSet$.\\
Шаг 2.3.2. Добавляем последним $currentVertice$ в $visitedVerticesArray$.\\
Шаг 2.3.3. $currentVector = prev_{iteration}[currentVector]$.\\
Шаг 2.3.4. $iteration--$.\\
Шаг 2.4. Цикл найден, восстанавливаем цикл по $visitedVerticesArray$ простым проходом от предпоследнего элемента к началу со сравнением элемента вектора с последним элементом вектора.\\
Шаг 2.5. Если $minMean$ больше среднего веса найденного цикла, то записываем в $minMean$ значение среднего веса этого цикла.\\
Шаг 3. Возвращаем $minMean$.\\ 
\end{algorithm}

Основной вопрос для данного алгоритма - это какое количество итераций $ITER$ мы должны взять, т.е. какой длины для $\Pi_{ITER}$ достаточно, чтобы обязательно существовал путь хотя бы к одной из вершин графа такой, что являлся бы путем минимального веса длины $ITER$ и при этом содержал по крайней мере один оборот по оптимальному циклу. Эмпирическими рассуждениями число $ITER$ было выставлено равным $3n$, базируясь на том, что длина предцикла, цикла и послецикла не может быть больше $n$ (поскольку из каждой вершины в каждую существует не более одного ребра; предцикл и послецикл не могут заходить в одну и ту же вершину дважды, поскольку в таком случае они зациклятся, а также простой цикл не может быть длиннее $n$).

\begin{theorem}
Асимптотическая сложность алгоритма нахождения $\Lambda$ с числом $ITER = 3n$ составляет $O(nm)$.
\end{theorem}
\textbf{Доказательство}
Как уже было доказано в Теореме 1, сложность нахождения $\Pi_1, \Pi_2, ..., \Pi_{3n}$ (как и сопутствующих векторов $prev_1, prev_2, ..., prev_{3n}$) составляет $O(3nm) = O(nm)$. Остается доказать, что нахождение циклов и вычисление их средних весов также асимптотически выполняется за $O(nm)$.

Действительно, рассматриваются только циклы, которые можно получить из легчайших путей, ведущих вершины. Т.е. как следует из Шага 2, внешний цикл совершает $n$ итераций. Из каждой вершины восстанавливается легчайший путь, ведущий в нее (это происходит на шагах 2.3.1 - 2.3.4). Поскольку послецикл и один оборот цикла вместе взятые не могут быть длиннее $2n$ шагов, то внутренний цикл (Шаг 2.3) совершает не более чем $2n$ итераций. На шаге 2.4 также неявно присутсвует цикл, заключающийся в обходе всех вершин найденного цикла (а их, как мы знаем, не больше чем $n$). Итого, асимптотическая сложность Шагов 2-3 составляет $O(n \cdot (2n + n)) = O(n^2)$. В таком случае общая сложность алгоритма нахождения $\Lambda$ составляет $O(nm) + O(n^2) = O(n(m+n))$. Но в силу особенностей графов разностных и линейных переходов (в них присутствует по крайней мере $n$ ребер), сложность алгоритма можно упростить до $O(nm)$.$\boxtimes$
\bigskip

К сожалению, точно доказать корректность алгоритма пока не удалось. Основной проблемой в доказательстве является необходимость доказать, что $3n$ итераций достаточно для достижения асимптотических свойств $\frac{\Pi_N}{N}$. Однако на рассмотренных тактовых подстановках это утверждение выполнялось.

Также в ходе исследования оказалось, что это известная задача в теории графов, обычно называемся mcm (minimum cycle mean). В течение преддипломной практики были изучены некоторые статьи, в которых описываются алгоритмы нахождения mcm ([7], [8]). Из подходящих нашей постановке задачи алгоритмов наилучшей асимтотической сложностью также является $O(nm)$.

\newpage
\section{Реализованные программы}

В ходе преддипломной практики был написан код, создающий схему $XS_1$ из файла, вычисляющий по схеме графы линейных и дифференциальных переходов, а также вычисляющий $\Pi_N$ по обоим графам с последующим вычислением mcm. Вся вышеозначенная функциональность реализована в двух классах: XS1 (лежит в файле XS1.py) и Graph (лежит в файле Graph.py). Использовать их можно двумя способами:

\begin{itemize}
\item Вызов из коммандной строки
\item Импорт соответствующих классов и использование их как API
\end{itemize}

Рассмотрим для каждого из файлов поотдельности, как их можно использовать.

\subsection{XS1.py}

В случае вызова из коммандной строки на вход должы подаваться полный путь к файлу с раширенной схемой, а также желаемый префикс к имени выходного файла. Рассмотрим на примере типичного вызова:

$python ~~~\sim/scripts/XS1.py~~~ \sim/schemes/feistel.txt~~~ \sim/graphs/feistel$

И теперь о каждом операнде поотдельности.

python означает вызов интерпретатора пайтона.

$\sim/scripts/XS1.py$, или, что то же самое, $/home/user/scripts/XS1.py$ - полный адрес до того скрипта, который вызывается.

$\sim/schemes/feistel.txt$ - полный адрес до файла, где записана расширенная матрица схемы XS1. Полагают, что элементы матрицы - это только 0 или 1, они разделены пробелами, а строки матрицы разделены символом новой строки.

$\sim/graphs/feistel$ - это префикс выходных файлов. Т.е. это означает, что после того, как скрипт отработал, по адресу $\sim/graphs/$ появится два файла, feistel\_lin.txt (в котором будет записан граф линейных переходов в виде матрицы смежности, элементы которой разделены запятыми, а строки - символом новой строки. Отсутствие ребра обозначается через -1) и feistel\_diff.txt (здесь будет записан  граф разностных переходов по соглашениям, аналогичным графу линейных переходов).

Помимо запуска из коммандной строки, можно просто совершить импорт класса к себе в код (для этого достаточно, чтобы файл с классом лежал в области видимости интерпретатора пайтона), и использовать функции, предоставляемые классом, для своих нужд.

\subsection{Graph.py}

В случае вызова из коммандной строки достаточно просто указать путь к файлу с графом (линейных или разностных переходов). Когда скрипт отработает, в командной строке напечатается mcm для данного графа. Т.е. так выглядит типичный вызов:

$python ~~~\sim/scripts/Graph.py~~~ \sim/schemes/feistel\_lin.txt$

python означает вызов интерпретатора пайтона.

$\sim/scripts/Graph.py$, или, что то же самое, $/home/user/scripts/Graph.py$ - полный адрес до того скрипта, который вызывается.

$\sim/schemes/feistel\_lin.txt$ - полный адрес до файла, где записан граф (в данном случае, граф линейных переходов) как матрица смежности. Полагают, что элементы матрицы - это только -1, 0 или 1 (где -1 означает отсутствие ребра), они разделены запятыми, а строки матрицы разделены символом новой строки.

\subsection{Доступ к коду}

Весь реализованный код находится в открытом доступе и может быть найден по ссылке: \url{https://github.com/mazukta26/Diploma}.

\subsection{Результаты экспериментов}

Были произведны вычисления minimum cycle mean на графах линейных и разностных переходов для некоторых известных тактовых подстановок. Результаты представлены в таблице ниже.
\newline

\begin{tabular}{ l | c | c }
  \hline			
  Схема & mcm на графе & mcm на графе \\
   & разностных переходов & линейных переходов \\
\hline
  Feistel & 0.(6) & 0.(6) \\
  Skipjack A & 0.5(3) & 0.5(3) \\
  Skipjack B & 0.5(3) & 0.5(3) \\
  SMS4 & 0.(857142) & 0.8 \\
  \hline  
\end{tabular}

\newpage
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
\vspace*{1cm}

В ходе преддипломной практики был разработан и реализован программно формат представления схем класса $XS_1$. Код, выполняющий чтение из файла матричного представления схемы и создающий объект схемы $XS_1$, можно найти в репозитории по ссылке, предоставленной в главе 5.2. Также был разработан формат представления графов и поддержан программно. Был разработан и реализован алгоритм, конвертирующий $XS_1$ схему в граф разностных переходов, и алгоритм, конвертирующий $XS_1$ схему в граф линейных переходов. Приведенные в отчете алгоритмы расчета динамических характеристик графа также были запрограммированы. Весь упомянутый код можно найти в репозитории на github.com, ссылка на который дана в подглаве 5.3.

Дальнейшим направлением работы является доказательство корректности приведенного алгоритма вычисления $\Lambda$ (или его опровержение), а также дальнейшее изучение статей по данной тематике с последующей программной реализацией алгоритмов, которые будут найдены в процессе поиска материалов по minimum cycle mean, и наилучшим образом будут соответствовать решаемой задаче.

\newpage
\section*{Список использованной литературы}
\addcontentsline{toc}{section}{Список использованной литературы}
\vspace*{1cm}

\begin{enumerate}
\item Ю.С. Харин, С.В. Агиевич, Д.В. Васильев, Г.В. Матвеев. Криптология.  Минск: БГУ,12-13, 511с, 2013.
\item В.Л. Цирлов. Основы информационной безопасности автоматизированных систем. Ростов-на-Дону: Феникс, 253с, 2008.
\item Ж. Брассар. Современная криптология. Москва: Полимед, 178с., 1999.
\item А.П. Алферов, А.Ю. Зубов, А.С. Кузьмин, А.В. Черемушкин. Основы криптографии. Москва: Гелиос АРВ, 480с., 2002.
\item Б.Шнайер. Прикладная криптография. Москва: Диалектика, 500с., 2003.
\item В.В. Марчук. Организация Перемешивания и усложнения при построении криптографических функций хэширования. Минск: БГУ, 51с., 2015.
\item A.Dasdan, S.S. Irani, R.K.Gupta. Efficient algorithms for optimum cycle mean and optimum cost to time ratio problems. USA: University of California and University of Illinois, 6с., 1999.
\item P. Butkovic, R.A. Cuninghame-Green. An $O(n^2)$ algorithm for the maximum cycle mean of an $n \times n$ bivalent matrix. 
\end{enumerate}
\end{large}

\end{document}