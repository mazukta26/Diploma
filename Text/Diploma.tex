\documentclass[a4paper,12pt]{report}
\setcounter{secnumdepth}{4}
\usepackage[utf8]{inputenc} % Кодировка utf8
\usepackage[english, russian]{babel} % Языки: русский, английский
\usepackage{color}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{totcount}
\usepackage{hyperref}
\usepackage{amssymb,amsthm,amsmath,amscd}
\ifx\pdfoutput\undefined
 \usepackage{graphicx}
 \else
 \usepackage[pdftex]{graphicx}
 \fi
\usepackage{float}
\usepackage{cite}
\usepackage{textcomp}
\usepackage{longtable}
\usepackage{xcolor}

%\usepackage[cp1251]{inputenc}

\usepackage{tocvsec2}

%для заголовков лонгтэйбла
\setlength{\LTcapwidth}{\linewidth}

%\lstdefinestyle{sharpc}{language=[Sharp]C, breaklines=true, rulecolor=\color{blue!80!black}}
\definecolor{bluekeywords}{rgb}{0.13,0.13,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.9,0,0}



\newtotcounter{citnum} %From the package documentation
\def\oldbibitem{} \let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citnum}\oldbibitem}




\lstset{language=[Sharp]C,
showspaces=false,
showtabs=false,
breaklines=true,
showstringspaces=false,
breakatwhitespace=true,
escapeinside={(*@}{@*)},
commentstyle=\color{greencomments},
keywordstyle=\color{bluekeywords}\bfseries,
stringstyle=\color{redstrings},
basicstyle=\ttfamily
}

%пакет cite служит для простой вставки ссылок на публикации в работе, если что,
%вызов этого пакета можно закомментировать с помощью символа %

%Оформление теорем, лемм и т.д.
\theoremstyle{plain} % default
\newtheorem{Theorem}{Теорема}[chapter]
\newtheorem{Lemma}{Лемма}[chapter]
\newtheorem{Proposition}{Предложение}[chapter]
\newtheorem{Corollary}{Следствие}[chapter]
\newtheorem{Statement}{Утверждение}[chapter]

\theoremstyle{definition}
\newtheorem{Definition}{Определение}[chapter]
\newtheorem{Conjecture}{Гипотеза}[chapter]
%\newtheorem{Algorithm}{Алгоритм}[chapter]
\newtheorem{Property}{Свойство}[chapter]

\theoremstyle{remark}
\newtheorem{remark}{Замечание}[chapter]
\newtheorem{example}{Пример}[chapter]
\newtheorem{Note}{Примечание}[chapter]
\newtheorem{Case}{Случай}[chapter]

%Определение полей
\setlength{\oddsidemargin}{0cm}% 1in=2.54см
\setlength{\hoffset}{0.46cm}% 1in+\hoffset=3cm = левое поле;

\setlength{\textwidth}{17cm}% 21cm-3cm(левое поле)-1cm(правое поле)=17cm;

\setlength{\headheight}{0cm}%
\setlength{\topmargin}{0cm}%
\setlength{\headsep}{0cm}%
\setlength{\voffset}{-0.54cm}% 1in+\voffset=2cm = верхнее поле;

\setlength{\textheight}{25.7cm}% 29.7cm-2cm(верхнее поле)-2cm(нижнее поле)=25.7cm;

%Оформление глав, разделов и т.д.
\makeatletter%

%не подавлять абзацный отступ в главах
\renewcommand{\chapter}{\cleardoublepage\thispagestyle{plain}%
\global\@topnum=0 \@afterindenttrue \secdef\@chapter\@schapter}

%оформление нумерованных глав
\renewcommand{\@makechapterhead}[1]{%Начало макроопределения
\vspace*{30pt}%Пустое место вверху страницы
{\parindent=16pt \normalfont\Large\center\bfseries
ГЛАВА \thechapter{}\\ %номер главы
\normalfont\Large\bfseries #1 \par %заголовок от текста
\nopagebreak %чтоб не оторвать заголовок от текста
\vspace{40 pt} %между заголовком и текстом
}%конец группы
}%коней макроопределения

%оформление ненумерованных глав
\renewcommand{\@makeschapterhead}[1]{%Начало макроопределения
\vspace*{30pt}%Пустое место вверху страницы
{\parindent=18pt \normalfont\Large\center\bfseries #1 \par %заголовок от текста
\nopagebreak %чтоб не оторвать заголовок от текста
\vspace{40pt} %между заголовком и текстом
}%конец группы
}%коней макроопределения

%оформление разделов
\renewcommand{\section}{\@startsection{section}{1}{18pt}%
{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}%
{\normalfont\Large\bfseries\raggedright}}%

%оформление подразделов
\renewcommand{\subsection}{\@startsection{subsection}{2}{18pt}%
{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}%
{\normalfont\large\bfseries\raggedright}}%

%оформление подподразделов
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{18pt}%
{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}%
{\normalfont\large\bfseries\raggedright}}%

%оформление библиографии

\renewcommand{\@biblabel}[1]{#1.}
%\renewcommand{\bibsection}{}
%\usepackage[english]{babel}
\addto{\captionsrussian}{ \renewcommand{\bibname}{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ\addcontentsline{toc}{chapter}{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}}}

\addto\captionsrussian{\renewcommand\figurename{Рисунок}}
\addto\captionsrussian{\renewcommand\figurename{Рисунок}}

%Оформление подписи рисунка
%\renewcommand \thefigure{\@arabic\c@figure}
%чтобы номер рисунка содержал номер главы (например, рисунок 2.1) надо закомментировать предыдущую строку
\renewenvironment{figure}{%
\let\@makecaption\@makefigurecaption
\@float{figure}}%
{%
\addtocontents{lof}{ {\vskip 0.4em} }%
\end@float%
}
%

\newcommand{\@makefigurecaption}[2]{%
\vspace{\abovecaptionskip}%
\sbox{\@tempboxa}{\large #1 --- \large #2}%
\ifdim \wd\@tempboxa >\hsize {\center\hyphenpenalty=10000\large #1 --- \large #2 \par}%
\else \global\@minipagefalse \hbox to \hsize
{\hfil \hyphenpenalty=10000 \large #1 --- \large #2\hfil}%
\fi \vspace{\belowcaptionskip}}

%Оформление подписи таблицы
%\renewcommand{\thetable}{\@arabic\c@table}
%чтобы номер таблицы содержал номер главы (например, таблица 2.1) надо закомментировать предыдущую строку
\renewenvironment{table}{%
\let\@makecaption\@maketablecaption
\@float{table}}%
{%
\addtocontents{lot}{ {\vskip 0.4em} }%
\end@float%
}
%




\newlength\abovetablecaptionskip
\newlength\belowtablecaptionskip
\newlength\tableparindent
\setlength\abovetablecaptionskip{10\p@}
\setlength\belowtablecaptionskip{0\p@}
\setlength\tableparindent{18\p@}
\newcommand{\@maketablecaption}[2]{
  \vskip\abovetablecaptionskip
  \hskip\tableparindent \large #1~---\ \large #2\par
  \vskip\belowtablecaptionskip
}

\makeatother%

\sloppy










\begin{document}
\thispagestyle{empty}
\vspace*{2cm}

\thispagestyle{empty}
\begin{normalsize}
\begin{center}
{\bf МИНИСТЕРСТВО ОБРАЗОВАНИЯ РЕСПУБЛИКИ БЕЛАРУСЬ}
\end{center}

\begin{center}
{\bf БЕЛОРУССКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ}
\end{center}

\begin{center}
{\bf ФАКУЛЬТЕТ ПРИКЛАДНОЙ МАТЕМАТИКИ И ИНФОРМАТИКИ}
\end{center}

\begin{center}
{\bf Кафедра математического моделирования и анализа данных}
\end{center}
\end{normalsize}
\bigskip
\bigskip
\bigskip
\begin{center}
{МИРОНОВИЧ Светлана Юрьевна}
\end{center}

\begin{center}
{\bf AS-СХЕМЫ ПОСТРОЕНИЯ ТАКТОВЫХ ПОДСТАНОВОК БЛОЧНЫХ КРИПТОСИСТЕМ: ХАРАКТЕРИСТИКИ ПЕРЕМЕШИВАНИЯ}
\end{center}
\bigskip
\bigskip
\begin{center}
Дипломная работа 
\end{center}
\begin{center}
специальность 1-98 01 01 <<Компьютерная безопасность>>
\end{center}
\bigskip
\bigskip
\linespread{1.0}
\begin{tabular}{@{}p{7cm}@{}p{10cm}}
{} & {Научный руководитель Сергей Валерьевич}\\
{} & {Агиевич}\\
{} & {кандидат физико-математических наук,}\\
{} & {заведующий НИЛ ПБИТ}\\
{} & {}\\
{} & {}\\
{} & {}\\
{Допущена к защите} & {}\\
\begin{picture}(140,15)\put(0,0){<<\line(1,0){20}>>\quad\put(0,0){\line(1,0){70}{~ 2017 г.}}}\end{picture} & {}\\
\end{tabular}
\newline
Зав. кафедрой математического\\
моделирования и анализа данных\\
\begin{picture}(71,15)\line(1,0){70}\end{picture} Ю.С. Харин\\
доктор физико-математических наук,\\
профессор,\\
член-корреспондент НАН Беларуси\\

\vspace{\stretch{1}}

\begin{center}
Минск, 2017
\end{center} 
\begin{large}
\newpage
{\linespread{1.10}\tolerance=2000
\renewcommand{\contentsname}{ОГЛАВЛЕНИЕ}
\tableofcontents} 
 
\clearpage

\chapter*{ОБЩАЯ ХАРАКТЕРИСТИКА РАБОТЫ}
\addcontentsline{toc}{chapter}{ОБЩАЯ ХАРАКТЕРИСТИКА РАБОТЫ}
Ключевые слова: ТАКТОВЫЕ ПОДСТАНОВКИ БЛОЧНЫХ КРИПТОСИСТЕМ, ОПЕРАЦИИ В ТАКТОВЫХ ПОДСТАНОВКАХ, ХАРАКТЕРИСТИКА ПЕРЕМЕШИВАНИЯ В КРИПТОСИСТЕМЕ, СПЕКТР ГРАФА, ЦИКЛ МИНИМАЛЬНОГО СРЕДНЕГО ВЕСА НА ГРАФЕ.

Цель работы --- разработка метрик, которые оценивают силу перемешивания в тактовой подстановке, и программного обеспечения, вычисляющего данные метрики.

Актуальность работы заключается в том, что ранее не исследовались характеристики перемешивания в криптосистемах с точки зрения теории графов.

Объект исследования --- тактовые подстановки с операциями XOR и подстановкой в S блоке, графы, описывающие зависимости в тактовой подстановке, а также метрики на данных графах.

В результате работы описаны алгоритмы построения графов, отражающих влияние битов в тактовой подстановке, разработаны метрики на данных графах, показывающие силу перемешивания в тактовой подстановке, а также написано программное обеспечение, которое строит данные графы и вычисляет по ним разработанные метрики.

Дипломная работа состоит из пяти глав: в первой главе описаны общие сведения и понятия, необходимые в дипломной работе, а также два возможных подхода к изучению характеристик перемешивания в тактовой подстановке; во второй главе рассматривается первый из подходов, связанный с графом зависимости тактовой подстановки; в третьей главе описан второй подход, основанный на графах линейных и разностных переходов; в четвертой главе описаны результаты вычисления метрик, представленных в главе 2 и главе 3, на некоторых известных криптосистемах; в пятой главе описаны программные инструменты, разработанные в ходе написания дипломной работы. В дипломную работу включено одно приложение. Объём работы --- \pageref{lastPage} листа, объём приложения --- 10 листов. Количество источников --- \total{citnum}.
\chapter*{АГУЛЬНАЯ ХАРАКТАРЫСТЫКА ПРАЦЫ}
Ключавыя словы: ТАКТАВЫЯ ПАДСТАНОЎКІ БЛОКАВЫХ КРЫПТАСІСТЭМ, АПЕРАЦЫІ Ў ТАКТАВЫХ ПАДСТАНОЎКАХ, ХАРАКТАРЫСТЫКА ПЕРАМЕШВАННЯ Ў КРЫПТАСІСТЭМЕ, СПЕКТРА ГРАФА, ЦЫКЛ МІНІМАЛЬНАЙ СЯРЭДНЯЙ ВАГІ НА ГРАФЕ.

Мэта працы --- распрацоўка метрык, якія ацэньваюць сілу перамешвання ў тактавай падстаноўке, і праграмнага забеспячэння, якое вылічваець дадзеныя метрыкі.

Актуальнасць працы складаецца ў тым, што раней не даследваліся характарыстыкі перамешвання ў крыптасістэмах з пункту погляду тэорыі графаў.

Аб'ект даследавання --- тактавыя падстаноўкі з аперацыямі XOR і падстаноўкай на S блоке, графы, якія апісваюць залежнасці ў тактавай падстаноўке, а таксама метрыкі на дадзеных графах. 

У выніку працы апісаны алгарытмы будавання графаў, якія адлюстроўваюць уплыванне бітаў ў тактавай падстаноўке, распрацованы метрыкі на дадзеных графах, якія паказваюць сілу перамешвання ў тактавай падстаноўке, а таксама напісана праграмная забеспячэнне, якое будуе дадзеныя графы і вылічвае па іх дадзеныя метрыкі.

Дыпломная работа складаецца з пяці раздзелаў: у першам раздзеле апісаны агульныя звесткі і паняцці, неабходныя ў дыпломнай рабоце, а таксама два магчымых падыхода да вывучэння характарыстык перамешвання ў тактавай падстаноўке; у другім раздзеле разглядаецца першый з падыходаў, звязаны з графам залежнасці ў тактавай падстаноўке; у трецім раздзеле апісаны другі падыход, заснаваны на графах лінейных і рознасных пераходаў; у чацвёртым раздзеле апісаны вынікі вылічэння метрык, прадстаўленных у раздзеле 2 і раздзеле 3, на некаторых вядомых крыптасістэмах; у пятым раздзеле апісаны праграмныя нструменты, распрацаваныя ў ходзе напісання дыпломнай работы. У дыпломную работу ўключана адно прыкладанне. Аб'ём працы --- \pageref {lastPage} лісты, аб'ём прыкладання --- 10 лістоў. Колькасць крыніц --- \total{citnum}.

\chapter*{ABSTRACT}
Keywords: CLOCK SUBSTITUTIONS OF BLOCK CRYPTOSYSTEMS, OPERATIONS IN CLOCK SUBSTITUTIONS, CHARACTERISTICS OF MIXING IN A CRYPTOSYSTEM, GRAPH SPECTR, MINIMUM CYCLE MEAN IN A GRAPH.

The goal of the thesis is development of metrics, that estimate the power of mixing in a clock substitution, and software, that calculates these metrics.

The relevance of the work lies in the fact that previously characteristics of mixing in a cryptosystem were not investigated from the standpoint of a graph theory.

The object of research are clock substitutions with XOR and substitution-box operations, graphs, that describe dependencies in a clock substitution, and metrics on such graphs. 

As a result the thesis describes algorithms of constructing the graphs, that show bit dependencies in a clock substitution, here were developed metrics on such graphs, and these metrics allow to see the power of mixing in a clock substitution, and also software that builds such graphs and calculates developed metrics was written.

The thesis constists of five chapters: the first chapter describes general knowledge and concepts necessary in the thesis, and also two possible approaches for investigating characteristics of mixing in a clock substitution; in the second chapter the first approach is considered. This approach is connected to dependency graph for a clock substitution. The third approach is described in the third chapter. The approach is based on linear and differential transitions graphs. In the fourth chapter is described results of metric from second and third chapters calculating on some well-known cryptosystems. In the fifth chapter the written for thesis software for metrics calculating and graph building is described. The thesis includes one appendix. The volume of the thesis is \pageref {lastPage} sheets, the volume of  the appendix is 10 sheets. The number of sources is \total{citnum}.


\newpage
\chapter*{ВВЕДЕНИЕ}
\addcontentsline{toc}{chapter}{ВВЕДЕНИЕ}

Современный мир невозможно представить без криптографии \cite{kripto}. Телефонные звонки, сообщения в социальных сетях, интернет-банкинг - все это требует специальныx средств для защиты данных каждого пользователя. Как никогда остро стоит вопрос целостности (т.е. уверенность, что данные не были изменены) и конфиденциальности (т.е. необходимость предотвращения утечки или разглашения) информации \cite{cirlov}. Таким образом, возможность сравнивать криптосистемы и находить наилучшую криптосистему из множества является не только интересной с точки зрения криптографии как науки, но и прикладной для многих бизнес задач.

С другой стороны, важной проблемой является быстродействие. Некоторые приложения в интернете, такие как видеозвоки, онлайн-трансляции, видеоконференции должны не только защищать целостность и конфиденциальность, но еще и работать "на лету". В данном случае важным параметром становится количество операций, необходимое для одного такта зашифрования.

Таким образом, для ряда задач требуются криптосистемы, которые при заданном числе операций являются наиболее криптостойкими по некоторой заданной метрике, при этом чем меньше операций, тем лучше.

На текущий момент в криптографии принято разделять все криптосистемы на два вида: симметричные, которые в преобразованиях зашифрования и расшифрования используют один и тот же ключ, и асимметричные, которым для зашифрования и расшифрования требуются разные ключи \cite{brassar}. Симметричные криптосистемы в свою очередь разделяются на блочные (когда исходный текст разбивается на блоки одинаковой длины и преобразование зашифрования применяется к каждому блоку) и поточные (когда генерируется гамма-последовательность, и шифртекст получается как результат применения операции XOR над исходным текстом и гамма-последовательностью) \cite{alferov}. 

Тактовую подстановку блочной криптосистемы можно задать схемой~---
ориентированным графом, который описывает ход вычислений. В работе мы будем говорить о криптосистемах как о схемах и рассматривать свойства именно схем.

Тактовые подстановки блочных криптосистем можно классифицировать по операциям, которые применяются в одном такте подстановки на каждом фрагменте. Используют следующие операции:

\begin{itemize}
\item R
\newline Операция циклического сдвига
\item L
\newline Логические операции И и ИЛИ
\item S
\newline Замена на S-блоке
\item X
\newline Применение операции XOR над двумя фрагментами
\item A
\newline Сложение фрагментов длины m как чисел по модулю $2^m$
\end{itemize}

Изначальная терминология предполагала, что A будет означать операцию XOR (и AS в названии дипломной работы предполагало именно операцию XOR), но впоследствии, чтобы иметь возможность различать XOR и сложение фрагментов длины m как чисел по модулю $2^m$ ввели A и X. Поэтому здесь и далее вместо аббревиатуры AS (означающего схемы с использованием XOR и замен на S-блоке) будем использовать аббревиатуру XS для больше прозрачности.

Различные сочетания операций дают различные типы схем. Так, криптосистемы SMS4 и Skipjack принадлежат к классу XS, AES можно отнести к классу XLS, а схемы криптосистем Salsa20, ChaCha и CAST-128 относятся к классу ARX \cite{schneier}.

Целью данной работы является исследование так называемых XS схем и предоставление метрик, способных сравнивать качество перемешивания в тактовых подстановках.

В дипломной работе описываются способы задания XS - схем и различные подходы к их изучению. Затем рассматривается детально каждый из подходов, при этом выводятся некоторые метрики для сравнения $XS_1$-схем. В конце описываются программные инструменты, вычисляющие данные метрики для некоторой заданной тактовой подстановки, а также значения метрик на некоторых известных тактовых подстановках, таких как belt-keywrap, Lei-Massey, Skipjack A и Skipjack B, Feistel и другие. Все программное обеспечение разработано на языке программирования python \cite{python} с использованием библиотеки для научных вычислений numpy \cite{numpy}.

\chapter{$XS_1$ СХЕМЫ. ПОДХОДЫ К ИЗУЧЕНИЮ ХАРАКТЕРИСТИК ПЕРЕМЕШИВАНИЯ В $XS_1$ СХЕМАХ}

\section{Общий вид и способ записи схем $XS_1$}

Пусть на вход поступает двоичное слово $X$, из которого в ходе зашифрования получают $Y$. Тактовые подстановки функционируют следующим образом: $X$ разбивается на $n$ равных по длине частей $X_1, X_2, X_3, ..., X_n \in \{0, 1\}^m, X = X_1||X_2||X_3||...||X_n$. Фрагменты $X_i$ интерпретируются как вектора длины $m$ над полем $\{0, 1\}$. Затем вычисляется $Y_i, i = \overline{1,n}$ как комбинация фрагментов $X_j$ с некоторыми операциями, такими как битовый сдвиг, исключающее ИЛИ, сумма по модулю $2^m$, замена на S блоке, логическое И, логическое ИЛИ и т.д. Затем фрагменты $Y_i$ объединяются, чтобы получить выходное значение $Y: Y = Y_1||Y_2||Y_3||...||Y_n$. Здесь $n$ называют размерностью схемы, а количество битов в $X_i$ или $Y_i$ обозначают $m$ - размером фрагмента.

Рассмотрим схемы, в которых есть только операции замены на S-блоке и исключающее ИЛИ. Обозначим такие схемы как $XS$, подразумевая, что $X$ в названии $XS$ означает исключающее ИЛИ (т.е. XOR), $S$ означает замену на $S$ блоке. 

Все $XS$ схемы можно разделить на классы в зависимости от того, сколько различных $S$ блоков используется внутри схемы. Так, $XS_k$ обозначает такую $XS$-схему, в которой присутствует $k$ различных $S$ блоков. Таким образом, будет справедливо следующее: $XS = XS_0 \cup XS_1 \cup XS_2 \cup ... \cup XS_k \cup...$ Можно также провести аналогичное разделение по количеству операций исключающего ИЛИ, необходимых для одного такта, т.е. $X_lS_k$ - схема с $l$ сложениями по модулю 2 и $k$ заменами на $S$ блоке. Понятно, что значения $l, k$ характеризуют сложность схемы: чем они больше, тем схема сложнее.

Основным объектом изучения будут схемы с одним блоком $S$ и неограниченным количеством операций XOR, т.е. схемы $XS_1$. К схемам $XS_1$ можно отнести ряд тактовых подстановок, таких как Skipjack A, Skipjack B, SMS4. 

Схемы $XS_1$ размерности $n$ можно задать в виде матрицы $B = (b_{ij})$ размерности $n \times n$, вектора-строки $c = (c_i)$ размерности $n$ и вектора-столбца $a=(a_i)$ размерности $n$ следующим образом:

$$u = a_1X_1 + a_2X_2 + ... + a_nX_n$$
$$v = S(u)$$
$$Y_i = b_{1i}X_1 + b_{2i}X_2 + ... + b_{ni}X_n + c_iv, \forall i = \overline{1,n}$$

Здесь "+" обозначает операцию сложения по модулю 2, а $b_{ij}, a_i, c_i \in \{0, 1\}$, и соответственно, если $b_{ij} = 0 \vee c_j=0 \vee a_j = 0$, мы полагаем, что соответствющий вектор $X_j$ не участвует в сложении по модулю 2. В случае же, когда $b_{ij} = 1 \vee c_j=1 \vee a_j = 1$, соответствующий вектор $X_j$ включается в сложение.

Соответственно, преобразование можно задать в матричной форме:

$$Y = XB + S(Xa)c, ~X = (X_1, X_2, X_3, ..., X_n)$$.

В таком случае, видно, что вся схема $XS_1$ однозначно задается тройкой $(a, B, c)$. 

Также удобно записывать $(a, B, c)$ в виде следующей матрицы, которую будем называть расширенной:

$$
\begin{pmatrix}
b_{11} & b_{12} & \ldots & b_{1n} & a_1\\
b_{21} & b_{22} & \ldots & b_{2n} & a_2\\
\dotfill\\
b_{n1} & b_{n2} & \ldots & b_{nn} & a_n\\
c_1    & c_2    & \ldots & c_n    & 0\\
\end{pmatrix}.
$$

Рассмотрим на примере тактовой подстановки Skipjack A:

$$u = X_1$$
$$v = S(u)$$
$$Y_1 = X_4 + v$$
$$Y_2 = v$$
$$Y_3 = X_2$$
$$Y_4 = X_3.$$

Или в виде расширенной матрицы:

$$
\begin{pmatrix}
0 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 0\\
1 & 0 & 0 & 0 & 0\\
1    & 1    & 0 & 0    & 0\\
\end{pmatrix}.
$$

\section{Подходы к изучению характеристик перемешивания в схемах $XS_1$}

В данной работе рассматриваются два различных подхода к изучению характеристик перемешивания тактовых подстановок. Различие подходов заключается в том, какие именно изучаются характеристики перемешивания: в одном случае мы изучаем перемешивание входных битов и их влияние на выходные, т.е. рассматривается тактовая подстановка в целом; в другом случае мы смотрим, насколько сильно "перемешиваются" входные биты в том смысле, что это затрудняет линейный или разностный криптоанализ, т.е. рассматриваются случаи более частного влияния.

Первый подход нацелен на изучение, какие входные биты влияют на конкретный выходной бит в некоторой заданной тактовой подстановке. Для этого строится граф зависимости, в котором из вершины $i$ ведет ребро в вершину $j$ тогда и только тогда, когда $i$-тый входной бит влияет на $j$-тый выходной бит. В данной работе рассматривается два типа графа зависимостей: индикаторный и вероятностный. Индикаторный граф зависимости характеризует наличие или отсутствие зависимости между битами; вероятностный граф зависимости нацелен не только показать наличие влияния, но и оценить относительную силу влияния одного бита на другой. На этим графах и их матрицах смежности можно определить некоторые характеристики, отражающие, насколько хорошо перемешиваются биты в данной криптосистеме.

Второй подход нацелен на выделение определенных свойств в графе и их подверженность атакам. Этот подход возник из работы \cite{marchuk}, где рассматриваются графы линейных и разностных переходов и поясняется их значение. Для нас же достаточно знать, что это ориентированные графы, ребрам которых приписаны веса 0 или 1, и подверженность тактовой подстановки атаке связана именно с весами ребер (ребро веса 0 означает подверженный атаке переход в тактовой подстановке, поэтому всегда более предпочтительны ребра с весом 1). Далее в данной работе будут рассмотрены способы построения этих графов, а также эффективные алгоритмы нахождения предложенных в \cite{marchuk} метрик на данных графах.

\chapter{ГРАФ ЗАВИСИМОСТИ И ЕГО ХАРАКТЕРИСТИКИ}

Как уже ранее упоминалось, первый подход связан с изучением влияния входных битов на выходные при помощи графа зависимости. Сначала рассмотрим, что такое матрица и граф зависимостей и как они связаны с тактовой подстановкой. На этом этапе будут описываться тактовые подстановки не только типа $XS_1$, но и тактовые подстановки с участием операций сложения по модулю $2^m$ и перестановкой бит. Затем опишем способы конструирования матрицы зависимости из операций, которые используются в тактовой подстановке, а также некоторые характеристики, которые можно вычислить по данной матрице. В конце главы сузим множество тактовых подстановок до $XS$ и рассмотрим, как это упрощает вычисление некоторых характеристик.

В данной главе будем полагать, что на вход преобразования зашифрования 
поступает сообщение $X\in\{0,1\}^n$. Зашифрование состоит 
в применении ключезависимых тактовых подстановок. 
Каждая такая подстановка, в свою очередь,
является композицией еще более простых преобразований.

Слова отождествляем с неотрицательными целыми числами,
причем младшими битами считаем первые биты.
Биты слов нумеруются от $0$ до $n-1$.
В частности, число $2^i$ отождествляется с двоичным словом,
в котором единственная единица находится в позиции $i$.

\section{Матрица зависимостей}

Все преобразование зашифрования представим в виде подстановки $\sigma$.

Подстановке $\sigma$, действующей на $\{0,1\}^n$, 
поставим в соответствие {\it матрицу зависимостей}~$A_\sigma=(a_{ij})$.
Элемент $a_{ij}$ этой матрицы характеризует влияние $i$-го
бита прообраза~$\sigma$ на $j$-й бит образа.

Степень влияния можно описывать по-разному.
Рассмотрим два варианта:
\begin{enumerate}
\item
{\it Индикаторы}: $a_{ij}=1$,
если изменение $i$-го бита $X$ может привести 
к изменению $j$-го бита $\sigma(X)$,
и $a_{ij}=0$ в противном случае.

\item
{\it Вероятности}: 
$$
a_{ij}=\Pr\big\{\sigma(X)_j\neq \sigma(X\oplus 2^i)_j\colon
X\stackrel{R}\leftarrow\{0,1\}^n\big\}.
$$
\end{enumerate}

Построим по $A_\sigma$ {\it граф зависимостей} $G_\sigma$.
Вершинами этого графа являются числа от~$0$ до~$n-1$.
Граф содержит дугу $(i,j)$, если $a_{ij}>0$,
причем этой дуге приписывается вес~$a_{ij}$.

Матрица $A_\sigma^d=(a_{ij}^d)$ описывает пути в~$G_\sigma$:
$a_{ij}^d$~--- это суммарный вес путей длины $d$ из вершины $i$
в вершину~$j$ (вес пути~--- это сумма весов его дуг).
Другими словами, $a_{ij}^d$ характеризует степень влияния 
$i$-го бита на $j$-й после $d$ итераций~$\sigma$.

Если матрица $A_\sigma$ составлена из индикаторов,
то~$\frac{1}{d}a_{ij}^d$~--- это общее число путей длины~$d$
из~$i$ в~$j$.

Для матрицы $A_\sigma$, составленной из вероятностей,
элементы $A_\sigma^d$ теряют вероятностный смысл.
В частности, они даже не остаются в отрезке~$[0,1]$.
%
Тем не менее, элементы~$A_\sigma^d$ сохраняют смысл силы 
влияния битов друг на друга.

Если $\sigma$ является композицией $\sigma_d\ldots\sigma_2\sigma_1$,
то
$$
A_\sigma=A_{\sigma_1}A_{\sigma_2}\ldots A_{\sigma_d}.
$$
Для тождественной подстановки $id$ матрица $A_{id}$
является единичной: $A_{id}=I_n$.

Если слово~$X$ разбито на части~$X_1,X_2,\ldots,X_d$ 
и~$\sigma(X)=\sigma_1(X_1)\parallel\sigma_2(X_2)\parallel\ldots\sigma_d(X_d)$,
то
$$
A_\sigma=
\begin{pmatrix}
A_{\sigma_1} & 0 & \ldots & 0\\
0 & A_{\sigma_2} & \ldots & 0\\
0 &   0          & \ldots & A_{\sigma_d}\\
\end{pmatrix}.
$$

Данные правила позволяют композиционно строить матрицы 
зависимостей для типовых криптографических преобразований.
Для этого достаточно только разобраться с элементарными преобразованиями, такими как перестановка битов, сложение по модулю 2, сложение по модулю $2^m$, подстановка в $S$ блоке.

\section{Элементарные преобразования на матрице зависимостей}

Рассмотрим, как выглядят матрицы зависимости для элементарных преобразований.


{\bf Перестановка битов}.
Пусть $X=x_1x_2\ldots x_n$
и $P(X)=X_{\pi(1)}X_{\pi(2)}\ldots X_{\pi(n)}$,
где $\pi$~--- перестановка чисел от $1$ до~$n$.
Тогда $A_P$~--- перестановочная матрица.
В частности, если $P$~--- циклический сдвиг,
то $A_P$~--- циркулянт. Сказанное относится
как к индикаторному, так и к вероятностному описаниям.

Например, пусть дана перестановка $P = (3~1~2)$. Тогда матрица $A_p$ примет вид:

$$
A_p = 
\begin{pmatrix} 
0 & 1 & 0\\ 
0 & 0 & 1\\ 
1 & 0 & 0\\
\end{pmatrix}.
$$

{\bf Сложение $\oplus$}.
Пусть $n$~--- четное, $m=n/2$,
$X=X_1\parallel X_2$, 
и $\oplus(X)=(X_1\oplus X_2)\parallel X_2$.
Тогда и в индикаторном, и в вероятностном описании 
матрица зависимости имеет вид:
$$
A_\oplus = 
\begin{pmatrix} 
I_m & 0\\ 
I_m & I_m 
\end{pmatrix}.
$$

{\bf Сложение $\boxplus$}.
Сохраняя соглашения предыдущей операции,
пусть $\boxplus(X)=(X_1\boxplus X_2)\parallel X_2$.
Тогда индикаторная матрица зависимости:
$$
A_\boxplus = 
\begin{pmatrix} 
U_m & 0\\ 
U_m & I_m 
\end{pmatrix}.
$$
Здесь~$U_m$~--- матрица с единицами на и выше главной диагонали,
и нулями ниже главной диагонали. Матрица~$U_m$ формализует 
следующее наблюдение: при сложении~$X_1\boxplus X_2$
$i$-й бит $X_1$ или $X_2$ влияет на биты суммы с номерами $j\geq i$,
и не влияет на биты с номерами $j<i$.

Например, $U_4$ имеет вид:

$$
U_m = 
\begin{pmatrix} 
1 & 1 & 1 & 1\\ 
0 & 1 & 1 & 1\\ 
0 & 0 & 1 & 1\\
0 & 0 & 0 & 1\\
\end{pmatrix}.
$$

В вероятностной матрице зависимостей матрица 
$U_m$ меняется на матрицу $P_m$ из элементов 
$$
p_{ij}=\begin{cases}
2^{i-j}, & j\geq i,\\
0,       & j< i.
\end{cases}
$$

Действительно,
найдем вероятность того, что $i$-тый бит $X_1$ повлияет на $j$-тый бит
$X_1\boxplus X_2$, $j\geq i$.
Имеем
\begin{align*}
p_{ij}
&= 
\Pr\bigg\{\big(X_1 \oplus 2^i)\boxplus X_2\big)_j \neq (X_1 \boxplus X_2)_j\colon
X_1, X_2\stackrel{R}\leftarrow \{0,1\}^n, X_{1,i} = 0\bigg\} =\\
&=
\Pr\bigg\{X_1+2^i+X_2\geq 2^j, X_1 + X_2 < 2^j\colon 
X_1, X_2\stackrel{R}\leftarrow\{0,1,\ldots,2^j-1\}, X_{1,i} = 0\bigg\}=\\
&=
\sum_{X_1\in \{0,1,\ldots,2^j-1\}, X_{1,i}=0}
\frac{1}{2^{j-1}}\Pr\bigg\{X_2 \in \{2^j-2^i-X_1,\ldots,2^j-1-X_1\}/X_1\bigg\} =\\
&=
\frac{2^{j-1}}{2^{j-1}}\cdot \frac{2^i}{2^j} = 2^{i-j}.
\end{align*}

Например, $P_4$ имеет вид:

$$
P_m = 
\begin{pmatrix} 
1 & 2^{-1} & 2^{-2} & 2^{-3}\\ 
0 & 1 & 2^{-1} & 2^{-2}\\ 
0 & 0 & 1 & 2^{-1}\\
0 & 0 & 0 & 1\\
\end{pmatrix}.
$$

{\bf Подстановка на $S$-блоках}.
Пусть $n=mr$, $S_1,S_2,\ldots,S_r$~---
криптографически надежные $S$-блоки,
действующие на слова длины~$m$ и 
пусть 
$$
S(X)=S(X_1\parallel X_2\parallel\ldots\parallel X_r)=
S_1(X_1)\parallel S_2(X_2)\parallel\ldots\parallel S_r(X_r),\quad
X_i\in\{0,1\}^m.
$$

Индикаторная матрица зависимостей:
$$
A_S = 
\begin{pmatrix} 
J_m & 0 & \ldots & 0\\ 
0 & J_m & \ldots & 0\\
  &     & \ldots &\\
0 &  0  & \ldots & J_m\\
\end{pmatrix}.
$$
Здесь~$J_m$~--- матрица порядка $m$ из всех единиц.
Матрица $J_m$ формализует следующий факт: 
криптографически надежный $S$-блок обеспечивает 
влияние каждого входного бита на каждый выходной.

В вероятностной матрице зависимостей матрица 
$J_m$ меняется на матрицу $\frac{1}{2}J_m$~---
вероятность изменения выходного бита при изменении 
входного в идеальном $S$-блоке равняется $\frac{1}{2}$. Т.е. вероятностная матрица зависимостей выглядит так:
$$
A_S = 
\begin{pmatrix} 
\frac{1}{2}J_m & 0 & \ldots & 0\\ 
0 &\frac{1}{2} J_m & \ldots & 0\\
  &     & \ldots &\\
0 &  0  & \ldots & \frac{1}{2}J_m\\
\end{pmatrix}.
$$

\section{Характеристики криптосистемы}

Теперь, когда формально описаны матрица и граф зависимостей, введем несколько характеристик на этих сущностях. Данные характеристики выбирались так, чтобы они отражали степень перемешивания входных значений в криптографическом преобразовании.

{\it Экспонентом} неотрицательной матрицы $A_\sigma$
(обозначается $\exp(A_\sigma)$)
называется натуральное $d$ такое, что 
$A_\sigma^d$ не содержит нулей.
В частности, $\exp(I_n)=\infty$, $\exp(J_n)=1$.

Если $\sigma$ описывает тактовую подстановку,
то $\exp(A_\sigma)$~--- это минимальное число тактов,
после которых все биты открытого текста повлияют 
на все биты шифртекста (время размножения ошибки).


Экспонент по сути является индикаторной характеристикой:
он учитывает факт влияния, но не его степень.
Более точная характеристика связана с теорией Ловаца
случайного блуждания на графах \cite{lovasz_walks}.

Для описания степени влияния задействуем спектр графа.

Спектром графа $G_{\sigma}$ называется набор собственных значений $\lambda_1, \lambda_2,...,\lambda_n$ его матрицы смежности $A_{\sigma}$. Этот набор отсортирован по убыванию модулей. 

Спектр характеризует некоторые важные свойства $G_{\sigma}$ \cite{lovasz_eigenvalues}, например:

\begin{enumerate}

\item Если граф $\Gamma$ неориентированный и нерегулярный, а максимальное по модулю собственное значение равно $\theta$, то справедливо $k_{min} < \overline{k} < |\theta| < k_{max}$, где $k_{min}, \overline{k}, k_{max}$ минимальная, средняя и максимальная степени вершин в графе соответственно.

\item У каждого графа $\Gamma$ существует действительное собственное значение $\theta_0$ с неотрицательным вещественным собственным вектором такое, что для любого собственного значения $\theta$ будет выполняться $|\theta| \leq \theta_0$.Значение $\theta_0(\Gamma)$ не возрастает, если из графа $\Gamma$ удалить вершины или ребра.

\item Пусть $\Gamma$ - полный граф на $n$ вершинах. Тогда его спектр будет следующим: $n-1,-1,-1,...,-1$.

\item Пусть $\Gamma$ - полный двудольный граф  с долями размера $m$ и $n$. Тогда его собственные значения следующие: $\sqrt{mn}, -\sqrt{mn},0,0,...,0.$

\end{enumerate}

Кроме этого, спектр описывает суммарный вес путей между вершинами $G_{\sigma}$. Действительно, суммарный вес для путей длины $d$ задается матрицей $A_{\sigma}^d$.

Пусть элементы спектра различны и отсортированы в порядке уменьшения модулей собственных значений. Обозначим их как $\lambda_1,\ldots, \lambda_n$, где $\lambda_1$ -- собственное значение с максимальным модулем. Тогда:

$A_{\sigma}^d = S \begin{pmatrix} 
\lambda_1 & 0 & \ldots & 0\\ 
0 & \lambda_2 & \ldots & 0\\
  &     & \ldots &\\
0 &  0  & \ldots & \lambda_n\\
\end{pmatrix}^d S^{-1} =  S \begin{pmatrix} 
\lambda^d_1 & 0 & \ldots & 0\\ 
0 & \lambda^d_2 & \ldots & 0\\
  &     & \ldots &\\
0 &  0  & \ldots & \lambda^d_n\\
\end{pmatrix} S^{-1}$

Здесь $S$ - некоторая фиксированная матрица. 

При помощи тождества выше можно оценить сверху элементы матрицы $A_{\sigma}^d$.

Отметим, что в теории Ловаца  случайных блужданий на графах \cite{lovasz_walks} важность представляет величина $k(A_{\sigma}) = \frac{|\lambda_2|}{|\lambda_1|}$. Эта величина характеризует скорость сходимости к стационарному распределению. Также из свойств выше видно, что показательным является значение $\lambda_1$. 

Обозначим за $exp(G)$ - экспонент матрицы, построенной по графу $G, \lambda(G)$ - первое  собственное значение матрицы смежности графа $G$, $k(G)$ - отношение второго модуля собственного значения к первому, т.е. $k(G) = \frac{|\lambda_2|}{|\lambda_1|}$.

Если $\sigma$ описывает тактовые подстановки, $d$~--- число тактов,
то число $k_\sigma^d$, объявляется характеристикой качества криптосистемы.

\section{Работа с XS схемами}

Дальнейшая работа связана с исследованием матриц зависимостей на XS схемах, а также изучением свойств параметра $exp(G)$ в зависимости от размера слова $n$ при одной и той же тактовой подстановке.

В качестве примера мы рассмотрим следующую схему: 
$$\Sigma(X_1||X_2||X_3||X_4)=(S(X_1\oplus X_2 \oplus X_3)\oplus X_4 || X_1 || X_2 || X_3)$$

Эта схема используется в китайском алгоритме шифрования SM4 (ранее алгоритм назывался SMS4).

Для этой схемы имеем следующие матрицы.

Индикаторная матрица:

$$
A_{\Sigma} = 
\begin{pmatrix} 
J_n & I_n & 0 & 0\\ 
J_n & 0 & I_n & 0\\
 J_n & 0 & 0 & I_n\\
I_n &  0  & 0 & 0\\
\end{pmatrix}.
$$

Вероятностная матрица:

$$
A_{\Sigma} = 
\begin{pmatrix} 
\frac{1}{2}
J_n & I_n & 0 & 0\\ 
\frac{1}{2}J_n & 0 & I_n & 0\\
\frac{1}{2} J_n & 0 & 0 & I_n\\
I_n &  0  & 0 & 0\\
\end{pmatrix}.
$$

Отметим, что матрицы составлены из блоков $O_m, I_m, J_m$, где-то домноженные на фиксированные константы.

Были проведены эксперименты по исследованию зависимости характеристик $exp(A_{\Sigma}), k(A_{\Sigma}),$ $\lambda(A_{\Sigma})$ от длины фрагмента $n$ (рассматривались $n=2,3,4,...,500$). Выяснилось, что экспонент не меняется, т.е. каким он был при $l=2$, таким он и остался для всех $l=3,4,...,500$ (экспонент оказался равен пяти) и для индикаторной матрицы, и для вероятностной. Также оказалось, что $k \rightarrow 0$ при $n \rightarrow \infty$, причем сходимость линейная. В частности, выполняется для индикаторной матрицы:

$$\frac{k_{256}}{k_{128}} = 0.5038.$$

И для вероятностной матрицы:

$$\frac{k_{256}}{k_{128}} = 0.505.$$

Также было замечено, что в индикаторной матрице $\lambda(A_{\Sigma}(n)) \rightarrow n$ и $\lambda(A_{\Sigma}(n)) \rightarrow \frac{n}{2}$ в вероятностной матрице.

\section{Независимость экспонента матрицы от размера фрагмента в матрицах зависимости $XS$ схем}

В предыдущем пункте на основании эмпирических наблюдений мы заметили, что экспонент матрицы не менялся с ростом $n$ - размером одного фрагмента. Докажем это строго.

Итак, у нас есть некоторая тактовая подстановка, такая что ее матрица зависимости состоит только из блоков $I(n), J(n), O(n)$ (заметим, что все тактовые подстановки из класса XS будут иметь именно такие матрицы зависимости). Цель - доказать свойство независимости экспонента от размера блока $n$.

Блоком мы будем называть матрицу размера $n \times n$.

%\textbf{Лемма}
\begin{Lemma}
Пусть у нас есть полоса из блоков $A_1, A_2, ..., A_r$ и столбец из блоков $B_1, ..., B_r$. Тогда:

$$(A_1, A_2, ..., A_r) \cdot (B_1, B_2, ..., B_r)^T = \sum_{i=1}^r A_iB_i$$
\end{Lemma}

\textbf{Доказательство}

Обозначим $a_{kl}^i$ - элемент $k$-той строки $l$-того столбца матрицы $A_i$; аналогично $b_{kl}^i$.

Пусть $C = (A_1, A_2, ..., A_k ) \cdot (B_1, B_2, ..., B_k)^T $, $D =  \sum_{i=1}^k A_iB_i$. Рассмотрим элемент $c_{kl}$:

$$c_{kl} = a^1_{k1}b^1_{1l} + ... +a^1_{kn}b^1_{nl} + ... +a^r_{kn}b^r_{nl} = \sum_{i=1}^r (a^i_{k1}b^i_{1l} + ... + a^i_{kn}b^i_{nl})$$

С другой стороны:

$$(A_iB_i)_{kl} = a^i_{k1}b^i_{1l} + ... + a^i_{kn}b^i_{nl}$$

А тогда:

$$d_{kl} = \sum_{i=1}^r (A_iB_i)_{kl} =  \sum_{i=1}^r (a^i_{k1}b^i_{1l} + ... + a^i_{kn}b^i_{nl}) = c_{kl}$$

$\boxtimes$

Введем понятие категорий блоков:

\begin{itemize}
\item Будем говорить, что блок принадлежит категории $A$, если в блоке стоят только нули.

\item Будем говорить, что блок принадлежит категории $B$, если в блоке на диагонали числа строго больше 0, вне диагонали - только нули.

\item Блок принадлежит категории $C$, если все числа в нем строго больше нуля.
\end{itemize}
Ясно, что матрицы $O(n), I(n), J(n)$ принадлежат категориям $A, B, C$ соответственно. Также очевидно, что эти категории блоков не покрывают все множество матриц. Например, верхнетреугольная недиагональная матрица не принадлежит ни к одной из категорий.

Нас интересует следующее утверждение: экспонент матрицы не зависит от $n, n \geq 2$. Докажем более сильное утверждение.

\begin{Statement}
Если перемножать матрицы, состоящие только из блоков одного размера, и каждый блок является представителем одной из категорий, описанных выше, то на выходе тоже получаем матрицу, состоящую из блоков того же размера, и каждый блок будет лежать в одной из категорий $A,B,C$. Причем то, какие категории будут на выходе, не зависит от $n$, а только от категорий, которые были на входе.
\end{Statement}
Ясно, что мы находим экспонент неотрицательной матрицы в тот момент, когда при возведении матрицы в некоторую степень мы получаем матрицу только из блоков категории $C$. И соответственно т.к. выбор категории после произведения не зависит от размера блока, то степень, при которой все блоки будут из категории $C$, не зависит от $n, n \geq 2$.

Построим "таблицу умножения" для категорий.

Очевидно, что какую бы матрицу мы не умножали на матрицу категории $A, ~\forall n \geq 2$, мы всегда получим на выходе матрицу категории $A$, т.е.:

$AA = A, AB = A, AC = A, BA = A, CA = A$

Также очевидно, что $BB = B, CC = C ~\forall n \geq 2$. Осталось только разобраться, что будет в случае $BC$ и $CB$.

Пусть матрица $D$ из категории $B$, матрица $E$ из категории $C$. Рассмотрим их произведения: $F = DE, G = ED$.

$$f_{ij} = \sum_{k=1}^n d_{ik}e_{kj}$$

Поскольку $E$ из категории $C$, то $\forall k,j: e_{kj} > 0$. Т.к. $D$ из категории $B$, то $d_{ik} = 0~ \forall k \neq i, d_{ii} > 0 \Rightarrow d_{ii}e_{ij} > 0, d_{ik}e_{kj} = 0~ \forall k \neq i \Rightarrow \sum_{k=1}^n d_{ik}e_{kj} = d_{ii}e_{ij} > 0 \Rightarrow f_{ij} > 0~ \forall i,j \Rightarrow F \in C ~\forall n \geq 2$.

Аналогично рассмотрим матрицу $G$:

$$g_{ij} = \sum_{k=1}^n e_{ik}d_{kj} = e_{ij}d_{jj} > 0 ~\forall i,j \Rightarrow G \in C ~\forall n \geq 2$$

Итого получаем следующую "таблицу умножения" категорий:

$AA = A, AB = A, AC = A, BA = A, BB = B, BC = C, CA = A, CB = C, CC = C ~\forall n \geq 2$.

Итак, очевидно следующее: при умножении блоков $E,D \in A \vee B \vee C$ вне зависимости от размера блока $n$ на выходе также получается блок одной из категорий $A,B,C$.

Поскольку нас интересуют не сами блоки из категорий $A,B,C$, а матрицы, состоящие из блоков этих категорий, и в лемме выше мы доказали, что произведение строки из блоков на столбец из блоков сводится к сложению произведений блоков, то ясно, что нужно еще рассмотреть сложение блоков категорий $A,B,C$. Таблица сложения не требует никаких доказательств в силу своей очевидности, поэтому просто приведем ее здесь:

$A+A = A, A+B = B, A+C = C, B+A = B, B+B = B, B+C = C, C+A = C, C+B = C, C+C = C$.

И здесь также очевидно, что результат сложения двух блоков из данных категорий не зависит от размера блока $n, n \geq 2$. А в таком случае т.к. категория результата произведения двух блоков из категорий $A,B,C$ не зависит от размера $n$, и категория результата сложения двух блоков из категорий $A,B,C$ не зависит от размера $n$, то и категория произведения строки из блоков на столбец из блоков, как следует из леммы, также не зависит от размера блоков. Но произведение двух матриц, состоящих из блоков категории $A, B$ и $C$ одного размера, сводится к произведению строки из блоков и столбца из блоков. Следовательно, категории блоков внутри матрицы произведения не будут менятся при изменении $n, n \geq 2$. А это означает, что степень, в которую надо возвести матрицу, состоящую из блоков $A,B,C$, чтобы получить матрицу из одних блоков $C$, не зависит от размера блока $n, n \geq 2$. А это и означает, что для $n \geq 2$ экспонент матрицы, состоящей исключительно из блоков $A,B,C$, не зависит от размера $n$. Заметим, что матрицы зависимости $XS$-схем полностью описываются блоками $A, B$ и $C$. А из этого вытекает справедливость следующей теоремы.

\begin{Theorem}
Экспонент матрицы зависимости некоторой тактовой подстановки, относящейся к классу XS, не зависит от выбора размера фрагмента.
\end{Theorem}

\chapter{ГРАФЫ ЛИНЕЙНЫХ И РАЗНОСТНЫХ ПЕРЕХОДОВ И ИХ ХАРАКТЕРИСТИКИ}

Как упоминалось в первой главе, вторым подходом к изучению характеристик перемешивания являются так называемые графы линейных и разностных переходов \cite{marchuk}. Данные графы отражают подверженность тактовой подстановки криптоатакам, а именно: граф линейных переходов отражает подверженность линейному криптоанализу; граф разностных переходов показывает слабые места с точки зрения разностного криптоанализа. 

Если $XS_1$ схема разбивает входное слово на $n$ блоков, то графы разностных и линейных переходов будут содержать $2^n$ вершин. Ребра данных графов ориентированные, и им приписаны веса. Вес может быть равен либо 0, либо 1, и вес 0 означает слабое место для определенной атаки.

\section{Граф разностных переходов}

Пусть у нас есть схема $XS_1$ с параметрами $(a, B, c)$. Обозначим ее как $E$,  $E(X)$ - результат подстановки $X$ в схему $E$. 

Пусть также в схему поступает два различных входа $X=X_1||X_2||...||X_n$ и $X'=X_1'||X_2'||X_3'||...||X_n'$, которые соответственно после проведения одного такта схемы преобразуются в $Y=Y_1||Y_2||Y_3||...||Y_n$ и $Y'=Y_1'||Y_2'||Y_3'||...||Y_n'$. Введем два вектора, $u$ и $v$ такие, что:

\begin{equation}
u_i=I\left\{X_i\ne X'_i\right\}=\left\{ \begin{array}{c}
1,X_i\ne X'_i \\
0,X_i=X'_i \end{array}
\right.i=1,\dots , n.
\end{equation}
\begin{equation}
v_i=I\left\{Y_i\ne Y'_i\right\}=\left\{ \begin{array}{c}
1,Y_i\ne Y'_i \\
0,Y_i=Y'_i \end{array}
\right.i=1,\dots , n.
\end{equation}

Будем называть $u$ разностным индикатором для $X$ и $X'$, и соответственно $v$ - это разностный индикатор $Y$ и $Y'$.

Говорят, из $u$ совершен разностный переход в $v$, когда существует два таких вектора $X$ и $X'$ такие, что $u$ - это их разностный индикатор, а $v$ является разностным индикаторов векторов $E(X) = Y, E(X') = Y'$.

$S$-блок при разностном переходе называется активным, если векторное произведение $(a, u) \neq 0$ (или, что то же самое, если $Xa \neq X'a$), поскольку в таком случае на вход $S$-блоку поступали разные вектора.

Тогда графом разностных переходов будем называть следующий ориентированный весовой граф. Его вершинами являются всевозможные битовые вектора длины $n$, и из вершины $u$ проведено ребро в вершину $v$ тогда и только тогда, когда из $u$ можно совершить разностный переход в $v$. Вес у этого ребра будет 1, если $S$-блок при таком разностном переходе является активным; в противном случае вес ребра будет 0.

Рассмотрим более подробно построоение графа разностных переходов на примере Skipjack A. Тактовая подстановка в Skipjack A выглядит, как упоминалось выше, следующим образом:

$$X_1, X_2, X_3, X_4 \rightarrow X_4 + S(X_1), S(X_1), X_2, X_3$$

Найдем, какие разностные переходы возможны из 1000.

Разностный индикатор 1000 для входных значений означает, что если нам на вход поступили вектора $X=X_1||X_2||X_3||X_4, X'=X_1'||X_2'||X_3'||X_4'$, то для них справедливо следующее: $X_1\neq X_1', X_2=X_2', X_3 = X_3', X_4 = X_4'$. 

Заметим, что поскольку $S$ биективна, то $A \neq B$ следует $S(A) \neq S(B)$.

Но в таком случае видно, что $Y_1=X_4 + S(X_1)=X_4' + S(X_1)\neq X_4' + S(X_1')=Y_1', Y_2=S(X_1)\neq S(X_1')=Y_2', Y_3=X_2=X_2'=Y_3', Y_4=X_3= X_3'=Y_4'$. Таким образом, разностный индикатор для $Y, Y'$ равен 1100. Более того, $S$-блок является активным.

Из этого следует, что в разностном графе существует ребро из 1000 в 1100 с весом 1, и аналогичным образом выстраиваются все ребра в графе разностных переходов.

Рассмотрим, как изменяются компоненты разностного индикатора при выполнении одного такта. Заметим, что поскольку мы имеем дело только с $XS_1$ схемами, нам достаточно рассмотреть, как влияют на разностный индикатор операторы исключающее ИЛИ и $S$-блок.


\textbf{$S$-блок}

Поскольку $S$-блок биективен, то $A \neq B$ тогда и только тогда, когда $S(A) \neq S(B)$. Это равносильно тому, что заметить следующее: пусть $u$ - некоторый разностный индикатор. Тогда если применить $S$-блок к фрагментам обоих исходных векторов, из которых получен данный разностный индикатор, и посчитать разностный индикатор результата (условно можем обозначить его $S(u)$), то снова получится вектор $u$, т.е. нули вектора $u$ перейдут в нули вектора $S(u)$, единицы перейдут в единицы. Или, что то же самое, $u=S(u)$.

\textbf{Исключающее ИЛИ}

 Как было доказано в \cite{marchuk}, для исключающего ИЛИ на разностных индикаторах (введем для этой операции специальное обозначение $\odot$) справедливы следующие соотношения:

\begin{itemize}
\item $0 \odot 0 = 0$
\item $0 \odot 1 = 1$
\item $1 \odot 0= 1$
\item $1 \odot 1 = 0$ и 1. 
\end{itemize}

Например, применим данную операцию к следующим векторам: 01101 и 11001. Получим:

$$01101 \odot 11001 = 1~_{1}^010~_{1}^0 = \{10100, 11100, 10101, 11101\}$$.

Введем также для удобства следующую бинарную операцию: $(u, v)^{\odot} = u_1v_1 \odot u_2v_2 \odot ... \odot u_nv_n$.

Поскольку мы знаем, как влияют операции $S$-блока и исключающее ИЛИ на разностные индикаторы, то мы можем теперь записать алгоритм построения графа разностных переходов:

\begin{algorithm}[H]
\caption{Алгоритм построения графа разностных переходов}
\label{diff_graph_construct}
\textbf{Вход:} $XS_1$-схема $(a, B, c), n$ - размерность схемы.\\
\textbf{Выход:} Граф разностных переходов для схемы $(a, B, c)$.\\
Шаг 0. Создаем квадратную матрицу res размера $2^n \times 2^n$ и заполняем ее -1. \\
Шаг 1. Для каждого вектора $v, v \in \{0, 1\}^n$ выполняем следующее: \\
Шаг 2.1 Вычисляем вес ребер $w$, исходящих из вершины, соответствующей вектору $v$, следующим образом: $w = 0~ if (a,v) = 0 ~else ~1$.\\
Шаг 2.2 Находим все вершины, куда ведут исходящие из $v$ ребра, следующим образом: $i$-тая координата вершины определяется как $(v, B_i)^{\odot} \odot c_iw$, где $B_i$ - это $i$-тый столбец $B$. \\
Шаг 2.3 Для всех найденных вершин $v'$, куда будут вести ребра из $v$, пишем $res[v][v'] = w$.
Шаг 3. Возвращаем $res$.\\
\end{algorithm}

Очевидно, что сложность алгоритма будет зависеть от входа $(a,B,c)$ и будет не превышать $2^{2n}$.

\section{Граф линейных переходов}

Пусть у нас есть схема $XS_1$ с параметрами $(a, B, c)$. Обозначим ее как $E$,  $E(X)$ - результат подстановки $X$ в схему $E$. 

Пусть также на вход тактовой подстановки поступает $X = X_1||X_2||...||X_n$, и $Y=E(X) = Y_1||Y_2||...||Y_n$.

Индикатором $q = (q_1, q_2, ..., q_n)$ для вектора $a=(a_1, a_2, ..., a_n)$ будем называть следующий вектор:

\begin{equation}
q_i=I\left\{a_i\ne 0\right\}=\left\{ \begin{array}{c}
1,a_i \neq 0 \\
0,a_i = 0\end{array}
\right.i=1,\dots , n.
\end{equation}

Рассмотрим следующее соотношение:

\begin{equation}
\label{eq:lin_proportion}
\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n
\end{equation}

Это соотношение должно выполняться для всех $X_1, X_2, ..., X_n$.

Понятно, что поскольку $Y_i$ является линейной комбинацией из $X_1, X_2, ..., X_n$, $S(a_1X_1 + a_2X_2 + ... + a_nX_n)$, то тогда соотношение можно переписать следующим образом:

\begin{equation}\label{eq:in_gamma}
\gamma_1X_1 + \gamma_2X_2 + ... + \gamma_nX_n = \gamma S(a_1X_1 + a_2X_2 + ... + a_nX_n)\end{equation}

Обозначим $q=(q_1, q_2, ..., q_n)$ как идентификатор для $\alpha=(\alpha_1, \alpha_2, ..., \alpha_n)$, $r=(r_1, r_2, ..., r_n)$ идентификатор для $\beta = (\beta_1, \beta_2, ..., \beta_n)$. И тогда про $q$ и $r$ можно сказать следующее: из $q$ совершен линейный переход в $r$, если \ref{eq:lin_proportion} выполняется для всех $X$. 

$S$-блок будет называться линейно активным, если $\gamma \neq 0$.

Теперь мы можем ввести определение графа линейных переходов. Графом линейных переходов будем называть такой ориентированный весовой граф, у которого вершинами являются вектора $\{0, 1\}^n$, и из вершины $q$ есть ребро в вершину $r$ тогда и только тогда, когда существуют такие $\alpha = (\alpha_1, \alpha_2, ..., \alpha_n)$, $\beta = (\beta_1, \beta_2, ..., \beta_n)$, что для любых $X_1, X_2, ..., X_n$ выполняется $\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n$, и притом $q, r$ являются соответственно индикаторами для $\alpha, \beta$. Ребро из $q$ в $r$ имеет вес 1, если $S$-блок является в данном соотношении линейно активным; иначе вес ребра равен 0.

Как было доказано в \cite{marchuk}, для соотношений выше справедливы следующие свойства:

 \begin{equation} \label{eq:lin_property1} 1) a_i = 0 \rightarrow \gamma_i = 0 \end{equation}
 \begin{equation} \label{eq:lin_property2} 2) a_i = a_j = 1 \rightarrow \gamma_i = \gamma_j  
 \end{equation}
\begin{equation} \label{eq:lin_property3} 3)(\ref{eq:in_gamma}) \Rightarrow \rho (Xa) = \gamma S(Xa) \end{equation}

Воспользуемся этими свойствами, чтобы найти всевозможные линейные соотношения. Для этого сначала распишем уравнение (\ref{eq:lin_proportion}) так, чтоб в нем не осталось $Y_1, Y_2, ..., Y_n$. Для этого сначала введем обозначения и запишем исходное соотношение:

$$v = S(a_1X_1 + a_2X_2 + ... + a_nX+n)$$
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1Y_1 + \beta_2Y_2 + ... + \beta_nY_n $$
Теперь распишем каждый $Y_i$ через $X_1, X_2, ..., X_n$.
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = \beta_1(b_{11}X_1 + b_{21}X_2 + ... + b_{n1}X_n + c_1v) +$$
$$ +  \beta_2(b_{12}X_1 + b_{22}X_2 + ... + b_{n2}X_n + c_2v) +$$
$$+~ ...~ +$$
$$+ \beta_n(b_{1n}X_1 + b_{2n}X_2 + ... + b_{nn}X_n + c_nv) $$
Затем перегруппируем в правой части слагаемые так, чтобы можно было выделить слагаемые с $X_1$, с $X_2$, ..., с $X_n$:
$$\alpha_1X_1 + \alpha_2X_2 + ... + \alpha_nX_n = (\beta_1b_{11} + \beta_2b_{12} + ... + \beta_nb_{1n})X_1 + $$
$$+(\beta_1b_{21} + \beta_2b_{22} + ... + \beta_nb_{2n})X_2 + ... + (\beta_1b_{n1} + \beta_2b_{n2} + ... + \beta_nb_{nn})X_n+$$
$$+ (\beta_1c_1 + \beta_2c_2 + ... + \beta_nc_n)v$$
И перенесем все слагаемые с $X_1, X_2, ..., X_n$ в левую часть, оставив в правой только те слагаемые, в которых присутствует $v$:
$$ (\alpha_1 + \beta_1b_{11} + \beta_2b_{12} + ... + \beta_nb_{1n})X_1 + (\alpha_2 + \beta_1b_{21} + \beta_2b_{22} + ... + \beta_nb_{2n})X_2 + $$
$$+...+ (\alpha_n + \beta_1b_{n1} + \beta_2b_{n2} + ... + \beta_nb_{nn})X_n =  (\beta_1c_1 + \beta_2c_2 + ... + \beta_nc_n)v$$
Перейдем теперь от векторов $\alpha_i, \beta_i$ к их индикаторам $\alpha_i', \beta_i'$ (и соответственно, переходим от операции исключающее ИЛИ к операции $\odot$):
$$ (\alpha_1' \odot \beta_1'b_{11} \odot \beta_2'b_{12} \odot ... \odot \beta_n'b_{1n})X_1 \odot (\alpha_2' \odot \beta_1'b_{21} \odot \beta_2'b_{22} \odot ... \odot \beta_n'b_{2n})X_2 \odot $$
$$\odot...\odot (\alpha_n' \odot \beta_1'b_{n1} \odot \beta_2'b_{n2} \odot ... \odot \beta_n'b_{nn})X_n =  (\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n)v = $$
\begin{equation}\label{eq:not_final_lin}=(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n)S(a_1X_1 \odot a_2X_2 \odot ... \odot a_nX_n)\end{equation}
И в таком случае видно, что для всех тех $i$, таких что $a_i = 0$, коэффициенты при $X_i$ должны зануляться, поскольку при $a_i = 0$ правая часть не зависит от $X_i$, и следовательно, от $X_i$ не должна зависеть и левая часть. Получаем следующее соотношение: 
$$\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = 0 ~ \forall i: ~a_i = 0$$
А для всех $i$ таких, что $a_i = 1$, ясно, что справедливо следующее:
$$\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = (\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i: ~a_i = 1$$
И теперь можем записать эти выражения в общем виде:
\begin{equation}\label{eq:slau}\alpha_i' \odot \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} = a_i(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i=\overline{1,n} \end{equation}
Или, если оставить $\alpha_i'$ на одной стороне, а $\beta_i'$ - на другой, получим:
\begin{equation}\label{eq:final_lin}\alpha_i' = \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} \odot a_i(\beta_1'c_1 \odot \beta_2'c_2 \odot ... \odot \beta_n'c_n) ~ \forall i=\overline{1,n} \end{equation}
Заметим также, что $S$-блок будет линейно активным, как следует из (\ref{eq:slau}), тогда и только тогда, когда  $\beta_1'c_1 + \beta_2'c_2 + ... + \beta_n'c_n=1$. Обозначим $weight = \beta_1'c_1 + \beta_2'c_2 + ... + \beta_n'c_n$, делая здесь отсылку к весу ребра в графе линейных переходов.

Тогда  (\ref{eq:final_lin}) перепишем так:

\begin{equation}\label{eq:final_lin_with_weight}\alpha_i' = \beta_1'b_{i1} \odot \beta_2'b_{i2} \odot ... \odot \beta_n'b_{in} \odot a_iweight ~ \forall i=\overline{1,n} \end{equation}

И теперь при помощи (\ref{eq:final_lin_with_weight}) можем записать алгоритм построения графа линейных переходов.

\begin{algorithm}[H]
\caption{Алгоритм построения графа линейный переходов}
\label{diff_graph_construct}
\textbf{Вход:} $XS_1$-схема $(a, B, c), n$ - размерность схемы.\\
\textbf{Выход:} Граф линейных переходов для схемы $(a, B, c)$.\\
Шаг 0. Создаем квадратную матрицу res размера $2^n \times 2^n$ и заполняем ее -1. \\
Шаг 1. Для каждого вектора $\beta, \beta \in \{0, 1\}^n$ выполняем следующее: \\
Шаг 1.1. Вычисляем возможные веса (потенциально может быть 2 веса одновременно: 0 и 1) как $weight=\beta_1'c_1 \odot \beta_2'c_2 \odot ... + \beta_n'c_n$\\
Шаг 1.2. Для каждого веса выполняем следующее:\\
Шаг 1.2.1 Находим все возможные $\alpha$, соответствующие этому $\beta$ и весу $weight$, подставляя $\beta, weight$ в \ref{eq:final_lin_with_weight}.\\
Шаг 1.2.2. Для каждого $\alpha$ записываем в матрицу $res$ следующее: $res[\alpha][\beta] = weight ~if~ res[\alpha][\beta] == -1 ~else~res[\alpha][\beta]=min(res[\alpha][\beta], weight)  $.\\
Шаг 2. Возвращаем $res$.\\
\end{algorithm} 

Следующее условие в алгоритме выше: $$res[\alpha][\beta] = weight ~if~ res[\alpha][\beta] == -1 ~else~res[\alpha][\beta]=min(res[\alpha][\beta], weight)$$ обусловлено тем, что потенциально возможна ситуация, когда из одной вершины в другую может идти два ребра, причем разных весов. В таком случае следует брать ребро веса ноль. Это связано с тем, что граф линейных переходов призван изучать слабые для линейных атак переходы в тактовой подстановке, и такие переходы в графе линейных переходов есть ни что иное, как ребро веса 0. А тогда из двух ребер, лежащих на одних и тех же вершинах, надо взять именно то ребро, которое показывает слабую сторону тактовой подстановки.

\section{Алгоритмы расчетов динамических характеристик графов переходов}

Для криптографической стойкости схемы важными характеристикиками являются следующие две величины \cite{marchuk}: минимальный вес пути заданной длины на графах линейных и разностных переходов, а также минимальноге отношение веса цикла к его длине на обоих графах.

Абстрагируемся от того, какой именно граф поступает нам на вход, линейных или разностных переходов, и просто обозначим его как $G$. Мы можем так поступить, поскольку свойства обоих графов очень схожи: оба графа являются ориентированными, у их ребер есть веса, причем вес может быть только 0 или 1, а также нет ребер, ведущих в вершину 000...0.

Для упрощения записи переименуем вершины графа $G$. В графах линейных и разностных переходов вершинами являются вектора из $\{0, 1\}^n$. Тогда пусть в $G$ вершин будут целыми числами, и тогда вершине $k$ из $G$ будет соответствовать на самом деле вершина $l$ из $\{0, 1\}^n$ такая, что $l$ - это битовая запись $k$.

\subsection{Минимальный вес пути заданной длины}

Будем полагать, что путь - это последовательность из вершин и ребер, которую можно записать следующим образом: $v_1, e_1, v_2, e_2, ..., e_mv_{m+1}$, где $e_i$ - это ребро, ведущее из $v_i$ в $v_{i+1}$. Тогда длина пути - это количество ребер в нем $m$, а вес - это сумма весов входящих в путь ребер. Также будем полагать, что ребра могут повторяться.

Обозначим как $V$ множество вершин графа $G$, $E$ - множество ребер графа $G$, $n$ - количество вершин в графе, $m$ - количество ребер в графе. Также пусть $(u, v) \in E$ - некоторое ребро, тогда его вес будем обозначать как $w(u, v)$.

Пусть нас интересует, какой минимальный вес пути длины $l$ на всем графе. Для этого будем искать пути минимального веса длины $l$ до каждой из вершин. Понятно, что вообще говоря кратчайший путь длины $l$ до любой из вершин может также и начинаться в любой вершине, поэтому сведем эту задачу к более известной: нахождение самого легкого пути длины $l$ до всех остальных вершин, причем путь всегда начинается из одной и той же вершины $v_{-1}$. Данная постановка задачи очень схожа с постановкой задачи в алгоритме Форда-Беллмана, в котором требуется найти легчайшие пути из заданной вершины до всех остальных (без учета длины). Вершина $v_{-1}$ является фиктивной, и будем полагать, что из $v_{-1}$ есть ребра до всех вершин из $V$, но нет ни одного ребра, ведущего в $v_{-1}$. Ребрам из $v_{-1}$ присвоим веса 0. В таком случае, нахождение легчайших путей длины $l$ до каждой из вершин в графе $G$ равнозначно нахождению легчайших путей длины $l+1$ из вершины $v_{-1}$ до всех остальных вершин.

 Рассмотрим алгоритм Беллмана-Форда и попытаемся модифицировать его согласно нашим нуждам.

\begin{algorithm}[H]
\caption{Алгоритм Беллмана-Форда}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$ и стартовая вершина $s$, от которой нужно найти вес легчайших путей до всех остальных вершин.\\
\textbf{Выход:} Массив $d$, в котором $d[v]$ содержит вес самого легкого пути из заданной вершины до вершины $v$.\\
Шаг 0. Создаем массив $d$ длины $n$ и заполняем его $+\infty$. \\
Шаг 1. Записываем $d[s] = 0$.\\
Шаг 2. Для $i$ от 1 до $n-1$ делаем следующее:\\
Шаг 2.1 Для всех ребер $(u, v) \in E:$\\
Шаг 2.1.1 Если $d[v] > d[u] + w(u,v)$, то $d[v] = d[u] + w(u,v)$\\
Шаг 3. Возвращаем $d$.\\
\end{algorithm}

Очевидно, сложность данного алгоритма $O(nm)$.

Видно, что основная проблема алгоритма Беллмана-Форда для нас заключается в том, что мы никак не фиксируем и не контролируем длину пути в ребрах. Теперь видоизменим алгоритм, и внешний цикл в нем сделаем не до $n$, а до $l$, где $l$ --- длина пути, чей минимальный вес мы ищем. Также на каждом шаге $k$ будем создавать новый массив $d_k$, в котором будут храниться минимальные веса длины $k$ до каждой из вершин. Запишем новый алгоритм:

\begin{algorithm}
\caption{Модифицированный Алгоритм Беллмана-Форда}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$.\\
\textbf{Выход:} Массив $\pi_l$, в котором $\pi_l[v]$ содержит самый легкий путь длины $l$ до вершины $v$.\\
Шаг 0. Создаем массив $\pi_0$ длины $n$ и заполняем его $0$. \\
Шаг 1. Для $k$ от 1 до $l$ делаем следующее:\\
Шаг 1.1 Создаем массив $\pi_k$ и заполняем его $+\infty$,\\
Шаг 1.2 Для всех ребер $(u, v) \in E:$\\
Шаг 2.1.1 Если $\pi_k[v] > \pi_{k-1}[u] + w(u,v)$, то $\pi_k[v] = \pi_{k-1}[u] + w(u,v)$\\
Шаг 3. Возвращаем $\pi_l$.\\
\end{algorithm}

\begin{Theorem}
Относительно модифицированного алгоритма Беллмана-Форда справедливо следующее:
1) Алгоритм решает задачу поиска кратчайших путей длины $l$ до каждой из вершин графа.
2) Вычислительная сложность предложенного алгоритма: $O(lm)$.
\end{Theorem}
\textbf{Доказательство}
Докажем каждое утверждение теоремы поотдельности.

1) Докажем данное утверждение методом индукции.

База индукции: на нулевом шаге в $\pi_0$ хранятся оптимальные веса.

Действительно, поскольку веса всех ребер неотрицательные, то и вес любого пути в графе обязательно $\ge$ 0. Следовательно, не может в графе существовать пути, вес которого меньше 0. Но на данном этапе в $\pi_0$ хранятся только нули, и следовательно, $\pi_0$ хранит минимальные по весу пути длины 0.

Индуктивный шаг: пусть на шагах $1, 2, ..., k-1$ были найдены минимальные по весу пути до каждой вершины длины $1, 2, ..., l-1$. Докажем, что и на $l$-том шаге будут найдены оптимальные пути. Положим от противного, это не так. Т.е. существует вершина $v'$, до которой существует путь длины $l: ~ v_1'e_1'v_2'e_2'v_3'...e_l'v'$, такой что $\sum_{i=1}^l w(e_i') < \pi_l[v']$. Но поскольку на шаге 1.2 алгоритма мы проходили по всем ребрам, мы должны были пройти и по ребру $(v_l', v')$. И поскольку $\pi_l[v'] > \sum_{i=1}^l w(e_i') = \pi_{l-1}[v_{l}'] + w( (v_l', v'))$, то на шаге 2.1.1 алгоритма мы должны были бы записать в $\pi_l[v'] = \pi_{l-1}[v_{l}'] + w( (v_l', v'))$, т.е. выбрать другой путь. И в таком случае на самом деле $\pi_l[v'] =  \sum_{i=1}^l w(e_i') $, и это противоречит предположению о том, что $\pi_l[v'] > \sum_{i=1}^l w(e_i')$. Следовательно, алгоритм действительно находит легчайшие пути заданной длины до всех вершин.

2) Это утверждение следует из того, что в алгоритме содержится только два вложенных цикла: один по длине пути, и один по всем ребрам. Один цикл повторяется $l$ раз, другой - $m$ (и оба цикла обязательно проходятся, т.е. нет пропуска итераций). Следовательно, сложность будет $O(lm)$.
$\boxtimes$

\bigskip

Теперь вспомним, что изначально нас интересовал путь наименьшего веса длины $l$ безотносительно того, где этот путь заканчивается. Обозначим данную величину за $\Pi_l$. Тогда очевидно, что искомая величина может быть найдена по $\pi_l$ следующим образом: $$\Pi_l = \min_{v \in V} \pi_l[v]$$.

\subsection{Цикл минимального среднего веса}

Постановка задачи звучит следующим образом: пусть у нас есть ориентированный граф $G$, ребрам которого присвоены веса. Требуется найти следующую величину:

$$\Lambda = \min _{c \in C} \frac{w(c)}{l(c)},$$

где $C$ - множество всех циклов графа $G$, $w(c)$ - вес цикла $c$, $l(c)$ - длина цикла $c$. Здесь длина цикла - это количество ребер в нем $n$, а вес цикла - это сумма весов всех входящих в него ребер.

Сначала в процессе исследований был предложен алгоритм, базирующийся на модифицированном алгоритме Беллмана-Форда. В основу были взяты рассуждения о том, что асимптотически величина $\frac{\Pi_N}{N}$ стемится к $\Lambda$.  И действительно, при $N \rightarrow \infty$ мы обязательно начнем ходить по какому-нибудь циклу. В таком случае величина $\Pi_N$ представима в виде суммы веса предцикла (т.е. тех ребер, с которых мы стартовали путь длины $N$ и которые не входят в цикл), цикла и послецикла (последние ребра, которые также не входят в цикл). Понятно, что длины предцикла и послецикла ограничены сверху количеством вершин в графе $n$. И тогда вес легчайшего пути при длине, стремящейся к бесконечности, может быть записан следующим образом:

$$\Pi_N = w(beforecycle) + $$
$$+\frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}w(cycle) + w(aftercycle)$$

Обозначим полное число оборотов, который совершит цикл, за $rot$, т.е. :

$$rot =  \frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}$$

Ограничим сверху и снизу величину $\Pi_N$, используя тот факт, что $0 \le w(beforecycle) \le n$ и $0 \le w(aftercycle) \le n$:

$$rot \cdot w(cycle) \le \Pi_N \le 2n + rot \cdot w(cycle).$$

И теперь разделим это выражение на длину пути в ребрах $N$:

\begin{equation}\label{eq:pi_divided_N}
\frac{rot}{N} \cdot w(cycle) \le \frac{\Pi_N}{N} \le \frac{2n}{N} + \frac{rot}{N} \cdot w(cycle).\end{equation}
Очевидно следующее:

$$\frac{rot}{N} w(cycle) = \frac{N - l(aftercycle) - l(beforecycle)}{l(cycle)}\frac{w(cycle)}{N}=$$
$$=\frac{N - l(aftercycle) - l(beforecycle)}{N}\frac{w(cycle)}{l(cycle)} =$$
$$= \frac{N - l(aftercycle) - l(beforecycle)}{N} \cdot mean(cycle) \rightarrow_{N \rightarrow \infty} mean(cycle)$$

Аналогично:

$$\frac{2n}{N} + \frac{rot}{N} \cdot w(cycle) \rightarrow mean(cycle)$$

А тогда из (\ref{eq:pi_divided_N}) при $N \rightarrow \infty$ следует:

$$mean(cycle) \le \lim_{N \rightarrow \infty} \frac{\Pi_N}{N} \le mean(cycle) \Rightarrow \lim_{N \rightarrow \infty}\frac{\Pi_N}{N} = mean(cycle)$$

Очевидно, что поскольку мы используем $\Pi_N$, которое означает минимальный вес пути длины $N$, то тогда и $mean(cycle)$ на самом деле будет использовать такой цикл, в котором средний вес минимален.

И тогда можно было бы находить величину $\Lambda$ при помощи величин в из массива $\pi_N$.

Заметим также, что нам достаточно находить простые циклы (т.е. те циклы, в которых каждая вершина встречается только один раз), поскольку любой цикл с повторениями вершин можно разбить на простые циклы, и среди простых циклов обязательно найдется цикл со значением среднего не больше, чем у исходного не простого цикла. Можно доказать это следующим образом: пусть нам дан исходный цикл из ребер $e_1, e_2, ..., e_k$ (вообще говоря, ребра могут повторяться. Порядок указания ребер также важен). Если этот цикл не является простым, то он обязательно разбивается на простые, причем следующим образом: в первый цикл входят ребра $e_1, e_2, ..., e_{k_1}$, во второй - $e_{k_1+1}, e_{k_1+2}, ..., e_{k_2}$, и так далее до последнего, $l$-того цикла $e_{k_{l-1}+1}, e_{k_{l-1}+2}, ..., e_{k_l},$ $(e_{k_l} = e_k)$.  Теперь положим от противного, средний вес всех простых циклов строго больше среднего веса исходного цикла. Обозначим средний вес исходного цикла за $mean_{src}$, а средние веса всех простых циклов как $mean_1, mean_2,$ $..., mean_l$. Но тогда мы получаем:

$$mean_{src} * k = w(e_1) + w(e_2) + ... + w(e_k) =$$
$$= k_1\frac{(w(e_1) +  w(e_2) +  ... + w(e_{k_1}))}{k_1} + k_2\frac{(w(e_{k_1+1}) + w(e_{k_1+2}) + ... + w(e_{k_2}))}{k_2} +$$
$$+ ... + k_l\frac{(w(e_{k_{l-1}+1}) + w(e_{k_{l-1}+2}) + ... + w(e_{k_l})}{k_l}) = $$
$$=k_1mean_1 ~+ ~k_2mean_2 ~+ ~... ~+ ~k_lmean_l~ >$$
$$> k_1mean_{src}~ +~ k_2mean_{src}~ +~ ...~ +~ k_lmean_{src} = (k_1 + k_2 + ... + k_l)mean_{src} = k \cdot mean_{src}$$

Т.е. мы получили следующее:

$$k \cdot mean_{src} > k \cdot mean_{src}$$

Это противоречие, и следовательно, предположение не верно. А это означает, что достаточно просматривать только простые циклы в графе, чтобы найти цикл минимального среднего веса.

Теперь, оперируя доказанными утверждениями (а именно то, что достаточно только простых циклов, а также утверждение про взаимосвязь $\Pi_N$ и $\Lambda$), составим алгоритм нахождения $\Lambda$ на основании модифицированного алгоритма Беллмана-Форда.

\begin{algorithm}[H]
\caption{Алгоритм нахождения $\Lambda$}
\label{diff_graph_construct}
\textbf{Вход:} Граф $G$\\
\textbf{Выход:} $\Lambda$.\\
Шаг 0. Вычислим все вектора $\Pi_i$ для $i = \overline{1, ITER}$. Также в процессе подсчета $\Pi_i$ создадим вектора $prev_i$, где $prev_i[v]$ хранит значение, из какой вершины был совершен последний переход в вершину $v$ по легчайшему пути длины $i$.\\
Шаг 1. Присваиваем $minMean = \infty$.\\
Шаг 2. Для каждой вершины $v \in V$, для которой справедливо $\Pi_{ITER}[v] \ne \infty$, делаем следующее:\\
Шаг 2.1. Восстанавливаем последний цикл, который содержится в легчайшем пути длины $ITER$, ведущим в $v$. Это вычисляется следующим образом:\\
Шаг 2.2. Создаем пустой вектор и пустое хэш-множество $visitedVerticesArray$ и $visitedVerticesSet$.\\
Шаг 2.3. Записываем $currentVertice = v; iteration = ITER$.\\
Шаг 2.3. Пока $currentVertice \notin visitedVerticesSet$:\\
Шаг 2.3.1. Добавляем $currentVertice$ в $visitedVerticesSet$.\\
Шаг 2.3.2. Добавляем последним $currentVertice$ в $visitedVerticesArray$.\\
Шаг 2.3.3. $currentVector = prev_{iteration}[currentVector]$.\\
Шаг 2.3.4. $iteration--$.\\
Шаг 2.4. Цикл найден, восстанавливаем цикл по $visitedVerticesArray$ простым проходом от предпоследнего элемента к началу со сравнением элемента вектора с последним элементом вектора.\\
Шаг 2.5. Если $minMean$ больше среднего веса найденного цикла, то записываем в $minMean$ значение среднего веса этого цикла.\\
Шаг 3. Возвращаем $minMean$.\\ 
\end{algorithm}

Основной вопрос для данного алгоритма - это какое количество итераций $ITER$ мы должны взять, т.е. какой длины для $\Pi_{ITER}$ достаточно, чтобы обязательно существовал путь хотя бы к одной из вершин графа такой, что являлся бы путем минимального веса длины $ITER$ и при этом содержал по крайней мере один оборот по оптимальному циклу. Эмпирическими рассуждениями число $ITER$ было выставлено равным $3n$, базируясь на том, что длина предцикла, цикла и послецикла не может быть больше $n$ (поскольку из каждой вершины в каждую существует не более одного ребра; предцикл и послецикл не могут заходить в одну и ту же вершину дважды, поскольку в таком случае они зациклятся, а также простой цикл не может быть длиннее $n$).

\begin{Theorem}
Асимптотическая сложность алгоритма нахождения $\Lambda$ с числом $ITER = 3n$ составляет $O(nm)$.
\end{Theorem}
\textbf{Доказательство}
Как уже было доказано в Теореме 1, сложность нахождения $\Pi_1, \Pi_2, ..., \Pi_{3n}$ (как и сопутствующих векторов $prev_1, prev_2, ..., prev_{3n}$) составляет $O(3nm) = O(nm)$. Остается доказать, что нахождение циклов и вычисление их средних весов также асимптотически выполняется за $O(nm)$.

Действительно, рассматриваются только циклы, которые можно получить из легчайших путей, ведущих вершины. Т.е. как следует из Шага 2, внешний цикл совершает $n$ итераций. Из каждой вершины восстанавливается легчайший путь, ведущий в нее (это происходит на шагах 2.3.1 - 2.3.4). Поскольку послецикл и один оборот цикла вместе взятые не могут быть длиннее $2n$ шагов, то внутренний цикл (Шаг 2.3) совершает не более чем $2n$ итераций. На шаге 2.4 также неявно присутсвует цикл, заключающийся в обходе всех вершин найденного цикла (а их, как мы знаем, не больше чем $n$). Итого, асимптотическая сложность Шагов 2-3 составляет $O(n \cdot (2n + n)) = O(n^2)$. В таком случае общая сложность алгоритма нахождения $\Lambda$ составляет $O(nm) + O(n^2) = O(n(m+n))$. Но в силу особенностей графов разностных и линейных переходов (в них присутствует по крайней мере $n$ ребер), сложность алгоритма можно упростить до $O(nm)$.$\boxtimes$
\bigskip

К сожалению, точно доказать корректность алгоритма пока не удалось. Основной проблемой в доказательстве является необходимость доказать, что $3n$ итераций достаточно для достижения асимптотических свойств $\frac{\Pi_N}{N}$. Однако на рассмотренных тактовых подстановках это утверждение выполнялось.

Также в ходе исследования оказалось, что это известная задача в теории графов, обычно называемся mcm (minimum cycle mean). В течение преддипломной практики были изучены некоторые статьи, в которых описываются алгоритмы нахождения mcm (\cite{dasdan}, \cite{butkovic}). Из подходящих нашей постановке задачи алгоритмов наилучшей асимтотической сложностью также является $O(nm)$.

\chapter{ПРАКТИЧЕСКИЕ РЕЗУЛЬТАТЫ ВЫЧИСЛЕНИЙ ХАРАКТЕРИСТИК ТАКТОВЫХ ПОДСТАНОВОК}

Как иллюстрацию выполненой работы рассмотрим, как работают предложенные алгоритмы на известных криптосистемах. В качестве примера значений метрик, описанных в главах 2 и 3, вычислим данные метрики на некоторых криптосистемах, таких как Feistel, Skipjack A, belt, belt keywrap, Lai-Massey и др.

В частности, были вычислены характеристики $k(G), \lambda(G), exp(G)$ для вероятностной и индикаторной матрицы зависимости криптосистемы belt. Результаты следующие.

Индикаторная матрица зависимости:

$$k(G) = 0.13326654881663205,$$
$$\lambda(G) = 109.7691521877077,$$
$$exp(G) = 2.$$

Вероятностная матрица зависимости:

$$k(G) = 0.3914373414043516,$$
$$\lambda(G) = 1027.8610668901583,$$
$$exp(G) = 2.$$

Также были произведны вычисления minimum cycle mean на графах линейных и разностных переходов для некоторых известных тактовых подстановок. Результаты представлены в таблице \ref{table:mcm_different}.

Наконец, были вычислены minimum cycle mean на графах линейных и разностных переходов для belt keywrap с различной длиной блока. Результаты отражены в таблице \ref{table:mcm_belt}.Здесь прослеживается зависимость с длиной блока. Так, mcm для графа разностных переходов описывается формулой $$\frac{n}{n+1},$$ где $n$ - длина блока. 

Также mcm для графа линейных переходов может быть описан формулой $$\frac{1}{n-1},$$ где $n$ также длина блока.

 Однако пока не удалось доказать, что эта закономерность будет прослеживаться и дальше при увеличении длины блока $n$.

\begin{table}
\caption{Результаты вычисления minimum cycle mean на графах линейных и разностных переходов различных тактовых подстановок}
\label{table:mcm_different}
\begin{center}
\begin{tabular}{ l | c | c }
  \hline			
  Схема & mcm на графе & mcm на графе \\
   & разностных переходов & линейных переходов \\
\hline
  Feistel & 0.(6) & 0.(6) \\
  Skipjack A & 0.5(3) & 0.5(3) \\
  Skipjack B & 0.5(3) & 0.5(3) \\
  SMS4 & 0.(857142) & 0.4 \\
  Lai-Massey & 1& 1 \\
  Matsui-L & 0.5 & 0.5 \\
  Matsui-R & 0.(6) & 0.(6) \\
  GFN-1 & 0.5(3) & 0.5(3) \\
  GFN-1-Inv & 0.5(3) & 0.5(3)  \\
  MARS-3 & 0.4 & 0 \\
  \hline  
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{Результаты вычисления minimum cycle mean на графах линейных и разностных переходов тактовой подстановки belt keywrap}
\label{table:mcm_belt}
\begin{center}
\begin{tabular}{ l | c | c }
  \hline			
  Длина блока & mcm на графе & mcm на графе \\
   & разностных переходов & линейных переходов \\
\hline
  2 & 0.(6) & 0.(6) \\
  3  & 0.75 & 0.5 \\
  4  & 0.8 & 0.(3) \\
  5 & 0.8(3) & 0.25 \\
  6 & 0.(857142) & 0.2 \\
  7 & 0.875 & 0.1(6) \\
  8 & 0.(8) & 0.(142857) \\
  9 & 0.9 & 0.125 \\
  10 & 0.(90) & 0.(1)  \\
  11 & 0.91(6) & 0.1 \\
  \hline  
\end{tabular}
\end{center}
\end{table}

\chapter{ОПИСАНИЕ ПРОГРАММНЫХ ИНСТРУМЕНТОВ}

В ходе написания дипломной работы были созданы инструменты для вычисления метрик, описанных в предыдущих главах. Рассмотрим поотдельности скрипты подходов из глав 2 и 3, как их вызывать и как их использовать.

\section{Скрипты для подхода 1: граф зависимости}

\subsection{dependency\_matrix\_operations.py}

Скрипт dependency\_matrix\_operations.py содержит функции, помогающие построить матрицу зависимости по элементарным операциям, которые фигурируют в тактовой подстановке. Для того, чтобы использовать функциональность данного скрипта, необходимо его заимпортировать в код как библиотеку. Внутри располагается класс ClockSubstitution, который является классом тактовой подстановки. При инициализации объекта этого класса нужно указать количество блоков, их размер, количество дополнительных блоков (для тех случаев, когда нужны дополнительные переменные для хранения временных значений), а также булевская переменная, отвечающая за то, вероятностную или индикаторную матрицу зависимости нужно построить. Значение ИСТИНА (True) соответствует вероятностной матрице зависимости. Например, для криптосистемы belt инициализация будет выглядеть следующим образом:

\begin{lstlisting}[language=Python]
belt = ClockSubstitution(4, 32, 1, True)
\end{lstlisting}
Здесь мы указываем, что нужно 4 блока по 32 бит, а также один дополнительный блок. На выходе нас интересует вероятностная матрица. Полагаем, что блоки нумеруются от 0. Также обращение к блоку -1 эквивалентно обращению к последнему блоку.

Рассмотрим операции, доступные для построения матрицы зависимостей:

\begin{itemize}
\item Операция XOR (исключающее ИЛИ, функция xor(block\_number1, block\_number2)).
\item Операция Addition (сумма по модулю $2^{block\_size}$, функция plus(block\_number1, block\_number2)).
\item Операция перестановки блоков местами (функция swap(block\_number1, block\_number2)).
\item Операция перестановки внутри блока (функция permutation(block\_number, permutation)). Перестановка permutation должна быть задана в виде упорядоченного набора чисел от 1 до block\_size (все числа должны обязательно встречаться, причем ровно по одному разу).
\item Операция G (специально создана для проверки работы на belt, функция g(block\_number, shift)).
\end{itemize}

Вот пример вызова для тактовой подстановки под названием subst, в которой вызывается операция XOR для 2 и 4 блоков:

\begin{lstlisting}
subst.xor(1, 3)
\end{lstlisting}
Для того, чтобы вывести матрицу зависимости, достаточно вызвать функцию dependency\_matrix:

\begin{lstlisting}
subst.dependency_matrix()
\end{lstlisting}

Также в функции create\_belt\_dependency\_matrix(), расположенной уже вне класса ClockSubstitution, полностью повторяется набор вызовов, необходимых для построения вероятностной матрицы зависимости для криптосистемы belt. Эту функцию можно рассмотреть как пример использования класса ClockSubstitution.

\subsection{calculate\_metrics.py}

В скрипте calculate\_metrics.py по имени файла, в котором через пробел и перенос строки описана матрица зависимости, вычисляются характеристики $exp(G), \lambda(G), k(G)$.

Пример вызова:

%\begin{lstlisting}
$python~~~calculate\_metrics.py~~~/path/to/dependency/matrix/belt.txt$
%\end{lstlisting}

\section{Скрипты для подхода 2: графы линейных и разностных переходов}

Для изучения подхода с графами линейных и разностных переходов был написан код, создающий схему $XS_1$ из файла, вычисляющий по схеме графы линейных и разностных переходов, а также подсчитывающий $\Pi_N$ по обоим графам с последующим вычислением mcm. Также был написан код для изучения свойств тактовой подстановки belt keywrap. Вся вышеозначенная функциональность реализована в двух классах: XS1 (лежит в файле XS1.py) и Graph (лежит в файле Graph.py). Также есть файл Main.py, в котором производится построение XS1 схемы для belt keywrap с различными размерами блока n с последующим вычислением значений mcm для обоих типов графов. 

 Использовать классы XS1 и Graph можно двумя способами:

\begin{itemize}
\item Вызов из коммандной строки
\item Импорт соответствующих классов и использование их как API
\end{itemize}

Рассмотрим для каждого из файлов поотдельности, как их можно использовать.

\subsection{XS1.py}

В случае вызова из коммандной строки на вход должы подаваться полный путь к файлу с раширенной схемой, а также желаемый префикс к имени выходного файла. Рассмотрим на примере типичного вызова:

$python ~~~\sim/scripts/XS1.py~~~ \sim/schemes/feistel.txt~~~ \sim/graphs/feistel$

И теперь о каждом операнде поотдельности.

python означает вызов интерпретатора python.

$\sim/scripts/XS1.py$, или, что то же самое, $/home/user/scripts/XS1.py$ - полный адрес до того скрипта, который вызывается.

$\sim/schemes/feistel.txt$ - полный адрес до файла, где записана расширенная матрица схемы XS1. Полагают, что элементы матрицы - это только 0 или 1, они разделены пробелами, а строки матрицы разделены символом новой строки.

$\sim/graphs/feistel$ - это префикс выходных файлов. Т.е. это означает, что после того, как скрипт отработал, по адресу $\sim/graphs/$ появится два файла, feistel\_lin.txt (в котором будет записан граф линейных переходов в виде матрицы смежности, элементы которой разделены запятыми, а строки - символом новой строки; отсутствие ребра обозначается через -1) и feistel\_diff.txt (здесь будет записан  граф разностных переходов по соглашениям, аналогичным графу линейных переходов).

Помимо запуска из коммандной строки можно просто совершить импорт класса к себе в код (для этого достаточно, чтобы файл с классом лежал в области видимости интерпретатора python), и использовать функции, предоставляемые классом, для своих нужд.

\subsection{Graph.py}

В случае вызова из коммандной строки достаточно просто указать путь к файлу с графом (линейных или разностных переходов). Когда скрипт отработает, в командной строке напечатается mcm для данного графа. Т.е. так выглядит типичный вызов:

$python ~~~\sim/scripts/Graph.py~~~ \sim/schemes/feistel\_lin.txt$

python означает вызов интерпретатора python.

$\sim/scripts/Graph.py$, или, что то же самое, $/home/user/scripts/Graph.py$ - полный адрес до того скрипта, который вызывается.

$\sim/schemes/feistel\_lin.txt$ - полный адрес до файла, где записан граф (в данном случае, граф линейных переходов) как матрица смежности. Полагают, что элементы матрицы - это только -1, 0 или 1 (где -1 означает отсутствие ребра; 0 или 1 - наличие ребра с соответствующим весом), они разделены запятыми, а строки матрицы разделены символом новой строки.

\subsection{Main.py}

Для запуска Main.py достаточно сделать вызов этого скрипта из коммандной строки:

 $python ~~~ main.py$

После того, как скрипт отработает, будет выведена статистика значений mcm для графов линейных и разностных переходов для belt keywrap с размерами блоков от 2 до 13.

\section{Доступ к коду}

Весь реализованный код находится в открытом доступе и может быть найден по ссылке: \url{https://github.com/mazukta26/Diploma}. В папке \url{https://github.com/mazukta26/Diploma/tree/master/DependencyMatrix} расположены скрипты для подхода с матрицей зависимости, т.е. подхода 1. По адресу \url{https://github.com/mazukta26/Diploma/tree/master/XS1} можно найти скрипты для подхода с графами линейных и разностных переходов, т.е. скрипты подхода 2.


\chapter*{ЗАКЛЮЧЕНИЕ}
\addcontentsline{toc}{chapter}{ЗАКЛЮЧЕНИЕ}

В работе получены следующие основные результаты:

\begin{itemize}
\item Разработано 2 подхода к изучению характеристик перемешивания в тактовых подстановках блочных криптосистем.
\item Написано ПО для работы с $XS_1$ схемами.
\item Разработаны и реализованы программно алгоритмы построения графов, отражающих перемешивание в тактовой подстановке.
\item Предложены и поддержаны программно метрики качества перемешивания в тактовой подстановке.
\item Предложенные метрики протестированы на известных тактовых подстановках.
\item Разработанное ПО может в дальнейшем применяться для исследования характеристик перемешивания в тактовых подстановках.
\end{itemize}


%\chapter*{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}
%\addcontentsline{toc}{chapter}{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}
%\addcontentsline{toc}{chapter}{СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ}
\begin{thebibliography}{99}
\bibitem{kripto} Математические и компьютерые основы криптологии: учеб. пособие / Ю.~С.~Харин [и др.]; под общ.ред. Ю. С. Харина. -- Минск: Новое знание, 2003. -- 382 с.
\bibitem{cirlov} Цирлов, В.Л. Основы информационной безопасности автоматизированных систем~/ В.~Цирлов.~--Ростов-на-Дону: Феникс, 2008.~---253~с.
\bibitem{brassar} Брассар, Ж. Современная криптология~/ Ж.~Брассар.~Москва: Полимед, 1999. ~---178~с.
\bibitem{alferov} Алферов, А. Основы криптографии~/ А.~Алферов.~Москва: Гелиос АРВ, 2002.~---480~с.
\bibitem{schneier} Шнайер, Б. Прикладная криптография~/ Б.~Шнайер.~Москва: Диалектика, 2003.~---500~с.
\bibitem{marchuk} Марчук, В. Организация перемешивания и усложнения при построении криптографических функций хэширования~/ В.~Марчук.~Минск: БГУ, 2015.~---51~с.
\bibitem{dasdan} Dasdan, A. Efficient algorithms for optimum cycle mean and optimum cost to time ratio problems~/ A.~Dasdan, S.~Irani, R.~Gupta. ~USA: University of California and University of Illinois, 1999.~---6 p.
\bibitem{butkovic} Butkovic, P. An $O(n^2)$ algorithm for the maximum cycle mean of an $n \times n$ bivalent matrix~/ P. Butkovic, R.A. Cuninghame-Green. UK: University of Birmingham, 1992.~---6 p.
\bibitem{lovasz_walks} Lovasz, L. Random walks on graphs: a survey~/ L.~Lovasz.~USA: Yale University, 1993.~---46 p.
\bibitem{lovasz_eigenvalues} Lovasz, L. Eigenvalues on graphs~/ L.~Lovasz. USA: Yale University, 2007.~---29 p.
\bibitem{python}Python documentation // Python documentation [Electronic resource].~--2017.-- Mode of access: \url{https://docs.python.org/3/}.~-- Date of access: 2017.02.23.
\bibitem{numpy}NumPy documentation // NumPy documentation [Electronic resource].~--2017.-- Mode of access: \url{https://docs.scipy.org/doc/}.~-- Date of access: 2017.02.23.
\end{thebibliography}
\end{large}
\label{lastPage}

\newpage
\renewcommand{\thechapter}{\Alph{chapter}}
\setcounter{chapter}{1}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}

\begin{flushright}
\normalfont\Large\bfseries ПРИЛОЖЕНИE A
\end{flushright}
\addcontentsline{toc}{chapter}{ПРИЛОЖЕНИЕ А}
%\addcontentsline{toc}{chapter}{Приложение А (Исходный код)}

\begin{center}
\normalfont\large\bfseries Исходный код разработанного программного обеспечения
\end{center}

\settocdepth{chapter}
\section{Подход 1: граф и матрица зависимости}
\subsection{Построение матрицы зависимости тактовой подстановки по ее операциям}
\begin{small}
 \lstinputlisting[language=Python]{../DependencyMatrix/dependency_matrix_operations.py}
\end{small}
\subsection{Вычисление метрик по матрице зависимости}
\begin{small}
 \lstinputlisting[language=Python]{../DependencyMatrix/calculate_metrics.py}
\end{small}

\section{Подход 2: графы линейных и разностных переходов}
\subsection{Класс, отвечающий за считывание XS1 схемы и построение по ней графов линейных и разностных переходов}
\begin{small}
 \lstinputlisting[language=Python]{../XS1/XS1.py}
\end{small}
\subsection{Класс, отвечающий за функционал графов, т.е. их хранение и вычисление по ним метрик}
\begin{small}
 \lstinputlisting[language=Python]{../XS1/Graph.py}
\end{small}
\subsection{Класс, содержащий основные эксперименты, проведенные с использованием графов линейных и разностных переходов}
\begin{small}
 \lstinputlisting[language=Python]{../XS1/Main.py}
\end{small}

\label{lastLastPage}
\end{document}